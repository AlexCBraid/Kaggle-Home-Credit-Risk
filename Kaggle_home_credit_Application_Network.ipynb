{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca506464-923e-4aa7-b3f9-347b1ff9a448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# Basic data manipulation and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Machine learning\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# Directory paths - adjust these based on your current setup\n",
    "# If you have directories defined somewhere in your code, we can use those variables\n",
    "DATA_DIR = \"/Users/braidosan/Downloads/home-credit-default-risk\"  # Update this to your actual path\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70dbc4da-0612-4007-90c3-952f6ae1dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_application_data():\n",
    "    \"\"\"Load main application data (train and test)\"\"\"\n",
    "    print(\"Loading application data...\")\n",
    "    train_df = pd.read_csv(os.path.join(DATA_DIR, \"application_train.csv\"))\n",
    "    test_df = pd.read_csv(os.path.join(DATA_DIR, \"application_test.csv\"))\n",
    "    print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "    return train_df, test_df\n",
    "\n",
    "def load_previous_applications():\n",
    "    \"\"\"Load previous applications data\"\"\"\n",
    "    print(\"Loading previous applications...\")\n",
    "    prev_df = pd.read_csv(os.path.join(DATA_DIR, \"previous_application.csv\"))\n",
    "    print(f\"Previous applications shape: {prev_df.shape}\")\n",
    "    return prev_df\n",
    "\n",
    "def load_bureau_data():\n",
    "    \"\"\"Load bureau data and bureau balance\"\"\"\n",
    "    print(\"Loading bureau data...\")\n",
    "    bureau_df = pd.read_csv(os.path.join(DATA_DIR, \"bureau.csv\"))\n",
    "    bureau_balance = pd.read_csv(os.path.join(DATA_DIR, \"bureau_balance.csv\"))\n",
    "    print(f\"Bureau shape: {bureau_df.shape}, Bureau balance shape: {bureau_balance.shape}\")\n",
    "    return bureau_df, bureau_balance\n",
    "\n",
    "def load_installments():\n",
    "    \"\"\"Load installments payments data\"\"\"\n",
    "    print(\"Loading installments...\")\n",
    "    installments = pd.read_csv(os.path.join(DATA_DIR, \"installments_payments.csv\"))\n",
    "    print(f\"Installments shape: {installments.shape}\")\n",
    "    return installments\n",
    "\n",
    "def load_credit_card_balance():\n",
    "    \"\"\"Load credit card balance data\"\"\"\n",
    "    print(\"Loading credit card balance...\")\n",
    "    cc_balance = pd.read_csv(os.path.join(DATA_DIR, \"credit_card_balance.csv\"))\n",
    "    print(f\"Credit card balance shape: {cc_balance.shape}\")\n",
    "    return cc_balance\n",
    "\n",
    "def load_pos_cash():\n",
    "    \"\"\"Load POS cash balance data\"\"\"\n",
    "    print(\"Loading POS cash balance...\")\n",
    "    pos_cash = pd.read_csv(os.path.join(DATA_DIR, \"POS_CASH_balance.csv\"))\n",
    "    print(f\"POS cash balance shape: {pos_cash.shape}\")\n",
    "    return pos_cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ba38b7-d4da-4bfa-873f-1c0516796960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading application data...\n",
      "Train shape: (307511, 122), Test shape: (48744, 121)\n",
      "Loading previous applications...\n",
      "Previous applications shape: (1670214, 37)\n"
     ]
    }
   ],
   "source": [
    "# Load only what we need initially - main application and previous applications\n",
    "train_df, test_df = load_application_data()\n",
    "prev_df = load_previous_applications()\n",
    "\n",
    "# We'll load other datasets when needed to manage memory\n",
    "# bureau_df, bureau_balance = load_bureau_data()\n",
    "# installments = load_installments()\n",
    "# cc_balance = load_credit_card_balance()\n",
    "# pos_cash = load_pos_cash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd35baae-3148-4f3f-bb5b-09f5b42a99a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing application-level data...\n",
      "Application-level data ready: (1413701, 38)\n",
      "TARGET distribution at application level:\n",
      "TARGET\n",
      "0    0.913447\n",
      "1    0.086553\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sample of application-level data:\n",
      "         SK_ID_CURR  SK_ID_PREV  TARGET  AMT_CREDIT  DAYS_DECISION\n",
      "395241       110288     2335913       0    225000.0           -478\n",
      "1102737      119604     2029099       0   1338493.5           -589\n",
      "744377       269213     1679002       0    241920.0           -300\n",
      "132249       352173     2780315       1     86656.5           -253\n",
      "1175071      215501     1598532       0     74182.5           -769\n"
     ]
    }
   ],
   "source": [
    "def prepare_application_level_data():\n",
    "    \"\"\"\n",
    "    Prepare data at the previous application level with TARGET from main application\n",
    "    \"\"\"\n",
    "    print(\"Preparing application-level data...\")\n",
    "    \n",
    "    # Get mapping from SK_ID_CURR to TARGET\n",
    "    # We need this to add TARGET to each previous application\n",
    "    target_mapping = train_df[['SK_ID_CURR', 'TARGET']].set_index('SK_ID_CURR')['TARGET'].to_dict()\n",
    "    \n",
    "    # Start with previous applications data\n",
    "    prev_apps = prev_df.copy()\n",
    "    \n",
    "    # Filter to keep only applications from customers in the training set\n",
    "    prev_apps = prev_apps[prev_apps['SK_ID_CURR'].isin(train_df['SK_ID_CURR'])]\n",
    "    \n",
    "    # Add TARGET to each previous application\n",
    "    prev_apps['TARGET'] = prev_apps['SK_ID_CURR'].map(target_mapping)\n",
    "    \n",
    "    # Check for any missing targets (shouldn't be any if filtering worked correctly)\n",
    "    missing_target = prev_apps['TARGET'].isnull().sum()\n",
    "    if missing_target > 0:\n",
    "        print(f\"Warning: {missing_target} previous applications have missing TARGET values\")\n",
    "        # Drop rows with missing TARGET\n",
    "        prev_apps = prev_apps.dropna(subset=['TARGET'])\n",
    "    \n",
    "    print(f\"Application-level data ready: {prev_apps.shape}\")\n",
    "    \n",
    "    # Display distribution of TARGET at application level\n",
    "    target_dist = prev_apps['TARGET'].value_counts(normalize=True)\n",
    "    print(f\"TARGET distribution at application level:\\n{target_dist}\")\n",
    "    \n",
    "    return prev_apps\n",
    "\n",
    "# Prepare application-level data\n",
    "app_level_data = prepare_application_level_data()\n",
    "\n",
    "# Display a sample of the data\n",
    "print(\"\\nSample of application-level data:\")\n",
    "print(app_level_data.sample(5)[['SK_ID_CURR', 'SK_ID_PREV', 'TARGET', 'AMT_CREDIT', 'DAYS_DECISION']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecbc304c-42ea-4d31-97d7-1399da15174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing application-level features...\n",
      "Preprocessing complete. Data shape: (1413701, 43)\n",
      "\n",
      "Feature information:\n",
      "Number of features: 40\n"
     ]
    }
   ],
   "source": [
    "def preprocess_app_level_features(app_level_data):\n",
    "    \"\"\"\n",
    "    Preprocess features for the application-level model\n",
    "    \"\"\"\n",
    "    print(\"Preprocessing application-level features...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = app_level_data.copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    for col in df.columns:\n",
    "        # Skip ID columns and TARGET\n",
    "        if col in ['SK_ID_CURR', 'SK_ID_PREV', 'TARGET']:\n",
    "            continue\n",
    "            \n",
    "        # Fill categorical missing values with 'Missing'\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna('Missing')\n",
    "            \n",
    "            # Label encode categorical columns\n",
    "            lbe = LabelEncoder()\n",
    "            df[col] = lbe.fit_transform(df[col])\n",
    "        else:\n",
    "            # Fill numerical missing values with median\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    # Create additional features from DAYS_DECISION\n",
    "    df['DAYS_DECISION_ABS'] = np.abs(df['DAYS_DECISION'])  # Absolute value\n",
    "    df['DAYS_DECISION_RECENT'] = np.exp(df['DAYS_DECISION'] / 100)  # Emphasize recent applications\n",
    "    \n",
    "    # Calculate some ratios that might be predictive\n",
    "    df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY'].replace(0, np.nan)\n",
    "    df['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE'].replace(0, np.nan)\n",
    "    df['DOWN_PAYMENT_TO_CREDIT'] = (df['AMT_GOODS_PRICE'] - df['AMT_CREDIT']) / df['AMT_CREDIT'].replace(0, np.nan)\n",
    "    \n",
    "    # Fill NaN from division with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # Check for any remaining missing values\n",
    "    missing_values = df.isnull().sum().sum()\n",
    "    if missing_values > 0:\n",
    "        print(f\"Warning: {missing_values} missing values remain after preprocessing\")\n",
    "    \n",
    "    print(f\"Preprocessing complete. Data shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# Preprocess application-level features\n",
    "app_level_features = preprocess_app_level_features(app_level_data)\n",
    "\n",
    "# Display feature information\n",
    "print(\"\\nFeature information:\")\n",
    "print(f\"Number of features: {app_level_features.shape[1] - 3}\")  # Exclude SK_ID_CURR, SK_ID_PREV, TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc18b938-499b-4c39-ae8f-120263e8d007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training application-level model...\n",
      "[LightGBM] [Info] Number of positive: 97888, number of negative: 1033072\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4512\n",
      "[LightGBM] [Info] Number of data points in the train set: 1130960, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.086553 -> initscore=-2.356468\n",
      "[LightGBM] [Info] Start training from score -2.356468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's auc: 0.630918\tvalid_0's binary_logloss: 0.285238\n",
      "\n",
      "Application-level model validation AUC: 0.6309\n",
      "\n",
      "Top 20 important features:\n",
      "                       feature  importance\n",
      "24            SELLERPLACE_AREA        2619\n",
      "1                  AMT_ANNUITY        2300\n",
      "15               DAYS_DECISION        2197\n",
      "37     CREDIT_TO_ANNUITY_RATIO        1967\n",
      "7      HOUR_APPR_PROCESS_START        1759\n",
      "35           DAYS_DECISION_ABS        1565\n",
      "2              AMT_APPLICATION        1426\n",
      "3                   AMT_CREDIT        1421\n",
      "6   WEEKDAY_APPR_PROCESS_START        1151\n",
      "38       CREDIT_TO_GOODS_RATIO        1041\n",
      "31   DAYS_LAST_DUE_1ST_VERSION        1008\n",
      "30              DAYS_FIRST_DUE         961\n",
      "39      DOWN_PAYMENT_TO_CREDIT         928\n",
      "32               DAYS_LAST_DUE         835\n",
      "4             AMT_DOWN_PAYMENT         821\n",
      "5              AMT_GOODS_PRICE         800\n",
      "33            DAYS_TERMINATION         777\n",
      "18             NAME_TYPE_SUITE         684\n",
      "23                CHANNEL_TYPE         682\n",
      "10           RATE_DOWN_PAYMENT         667\n"
     ]
    }
   ],
   "source": [
    "def train_app_level_model(app_level_features, random_state=42):\n",
    "    \"\"\"\n",
    "    Train the application-level model (Stage 1)\n",
    "    \"\"\"\n",
    "    print(\"Training application-level model...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    features = app_level_features.drop(['SK_ID_CURR', 'SK_ID_PREV', 'TARGET'], axis=1)\n",
    "    target = app_level_features['TARGET']\n",
    "    \n",
    "    # Split data for validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        features, target, test_size=0.2, random_state=random_state, stratify=target\n",
    "    )\n",
    "    \n",
    "    # Define the LightGBM model\n",
    "    model = lgbm.LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=32,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_weight=2,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgbm.early_stopping(stopping_rounds=100, verbose=True)]\n",
    "    )\n",
    "    \n",
    "    # Generate predictions for all applications\n",
    "    all_predictions = model.predict_proba(features)[:, 1]\n",
    "    \n",
    "    # Add predictions back to the dataframe\n",
    "    app_level_preds = app_level_features[['SK_ID_CURR', 'SK_ID_PREV']].copy()\n",
    "    app_level_preds['APP_PRED'] = all_predictions\n",
    "    \n",
    "    # Show model performance\n",
    "    val_preds = model.predict_proba(X_val)[:, 1]\n",
    "    val_auc = roc_auc_score(y_val, val_preds)\n",
    "    print(f\"\\nApplication-level model validation AUC: {val_auc:.4f}\")\n",
    "    \n",
    "    # Show feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 important features:\")\n",
    "    print(feature_importance.head(20))\n",
    "    \n",
    "    return app_level_preds, model\n",
    "\n",
    "# Train application-level model\n",
    "app_level_preds, app_level_model = train_app_level_model(app_level_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77516ba3-2d23-443b-bfb4-b37697fb578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating application-level predictions by customer...\n",
      "Aggregated predictions shape: (291057, 8)\n",
      "\n",
      "Sample of aggregated predictions:\n",
      "        SK_ID_CURR  APP_PRED_MEAN  APP_PRED_MAX  APP_PRED_MIN  APP_PRED_STD  \\\n",
      "231160      382531       0.083107      0.100546      0.050397      0.028349   \n",
      "148045      281405       0.099963      0.099963      0.099963      0.000000   \n",
      "35965       143951       0.055676      0.070629      0.041527      0.011905   \n",
      "65802       180592       0.085423      0.085423      0.085423      0.000000   \n",
      "71014       187014       0.072075      0.076678      0.067472      0.006510   \n",
      "\n",
      "        APP_PRED_COUNT  APP_PRED_RANGE  APP_PRED_COUNT_NORM  \n",
      "231160               3        0.050149             1.386294  \n",
      "148045               1        0.000000             0.693147  \n",
      "35965                4        0.029101             1.609438  \n",
      "65802                1        0.000000             0.693147  \n",
      "71014                2        0.009206             1.098612  \n"
     ]
    }
   ],
   "source": [
    "def aggregate_app_predictions(app_level_preds):\n",
    "    \"\"\"\n",
    "    Aggregate application-level predictions by customer\n",
    "    \"\"\"\n",
    "    print(\"Aggregating application-level predictions by customer...\")\n",
    "    \n",
    "    # Group by customer ID and calculate statistics of the predictions\n",
    "    agg_preds = app_level_preds.groupby('SK_ID_CURR').agg({\n",
    "        'APP_PRED': ['mean', 'max', 'min', 'std', 'count']\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    agg_preds.columns = ['APP_PRED_' + col for col in ['MEAN', 'MAX', 'MIN', 'STD', 'COUNT']]\n",
    "    \n",
    "    # Reset index\n",
    "    agg_preds = agg_preds.reset_index()\n",
    "    \n",
    "    # Handle missing std values (customers with only one application)\n",
    "    agg_preds['APP_PRED_STD'] = agg_preds['APP_PRED_STD'].fillna(0)\n",
    "    \n",
    "    # Add range feature\n",
    "    agg_preds['APP_PRED_RANGE'] = agg_preds['APP_PRED_MAX'] - agg_preds['APP_PRED_MIN']\n",
    "    \n",
    "    # Add normalized count (log transform to handle skewness)\n",
    "    agg_preds['APP_PRED_COUNT_NORM'] = np.log1p(agg_preds['APP_PRED_COUNT'])\n",
    "    \n",
    "    print(f\"Aggregated predictions shape: {agg_preds.shape}\")\n",
    "    \n",
    "    # Display sample of aggregated predictions\n",
    "    print(\"\\nSample of aggregated predictions:\")\n",
    "    print(agg_preds.sample(5))\n",
    "    \n",
    "    return agg_preds\n",
    "\n",
    "# Aggregate application-level predictions\n",
    "agg_preds = aggregate_app_predictions(app_level_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f207376c-6eb2-4127-84d3-e2d9379886a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing main model data with aggregated predictions...\n",
      "Customers with previous applications: 291057 (94.65%)\n",
      "Training data with predictions shape: (307511, 129)\n"
     ]
    }
   ],
   "source": [
    "def prepare_main_model_data(train_df, test_df, agg_preds):\n",
    "    \"\"\"\n",
    "    Prepare data for main customer-level model (Stage 2)\n",
    "    \"\"\"\n",
    "    print(\"Preparing main model data with aggregated predictions...\")\n",
    "    \n",
    "    # Add aggregated predictions to training data\n",
    "    train_with_preds = train_df.merge(agg_preds, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    # Fill missing values for customers with no previous applications\n",
    "    for col in ['APP_PRED_MEAN', 'APP_PRED_MAX', 'APP_PRED_MIN']:\n",
    "        # For customers with no previous applications, use a default value\n",
    "        # We could use the overall mean, but 0.5 is a reasonable default for a probability\n",
    "        train_with_preds[col] = train_with_preds[col].fillna(0.5)\n",
    "    \n",
    "    train_with_preds['APP_PRED_STD'] = train_with_preds['APP_PRED_STD'].fillna(0)\n",
    "    train_with_preds['APP_PRED_RANGE'] = train_with_preds['APP_PRED_RANGE'].fillna(0)\n",
    "    train_with_preds['APP_PRED_COUNT'] = train_with_preds['APP_PRED_COUNT'].fillna(0)\n",
    "    train_with_preds['APP_PRED_COUNT_NORM'] = train_with_preds['APP_PRED_COUNT_NORM'].fillna(0)\n",
    "    \n",
    "    # Check how many customers have previous applications\n",
    "    has_prev_apps = train_with_preds['APP_PRED_COUNT'] > 0\n",
    "    print(f\"Customers with previous applications: {has_prev_apps.sum()} ({has_prev_apps.mean()*100:.2f}%)\")\n",
    "    \n",
    "    # The test data won't have aggregated predictions yet since we haven't run the application model on it\n",
    "    # We'll deal with this later\n",
    "    \n",
    "    print(f\"Training data with predictions shape: {train_with_preds.shape}\")\n",
    "    \n",
    "    return train_with_preds, test_df\n",
    "\n",
    "# Prepare main model data\n",
    "train_with_preds, test_df = prepare_main_model_data(train_df, test_df, agg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23b3b8f0-cc52-4390-8359-0c9ecabd3484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data...\n",
      "Preprocessing complete. Data shape: (307511, 132)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_main_data(df, is_training=True):\n",
    "    \"\"\"\n",
    "    Preprocess the main dataset for model training\n",
    "    \"\"\"\n",
    "    print(f\"Preprocessing {'training' if is_training else 'test'} data...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying original data\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Define columns to drop\n",
    "    cols_to_drop = ['SK_ID_CURR']\n",
    "    if is_training:\n",
    "        # TARGET is not dropped from training data\n",
    "        pass\n",
    "    \n",
    "    # Handle missing values in numerical columns\n",
    "    num_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in num_cols:\n",
    "        # Skip TARGET and identifier columns\n",
    "        if col in ['TARGET', 'SK_ID_CURR']:\n",
    "            continue\n",
    "            \n",
    "        # Replace infinity values with NaN\n",
    "        data[col] = data[col].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Fill NaN with median\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "    \n",
    "    # Handle categorical columns\n",
    "    cat_cols = data.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        # Fill missing with 'Unknown'\n",
    "        data[col] = data[col].fillna('Unknown')\n",
    "        \n",
    "        # Label encode categorical variables\n",
    "        if col not in cols_to_drop:\n",
    "            le = LabelEncoder()\n",
    "            data[col] = le.fit_transform(data[col])\n",
    "    \n",
    "    # Create some additional features\n",
    "    \n",
    "    # Age in years (negative because DAYS_BIRTH is negative)\n",
    "    if 'DAYS_BIRTH' in data.columns:\n",
    "        data['AGE_YEARS'] = -data['DAYS_BIRTH'] / 365\n",
    "    \n",
    "    # Credit to income ratio\n",
    "    if 'AMT_CREDIT' in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n",
    "        data['CREDIT_TO_INCOME_RATIO'] = data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    # Annuity to income ratio\n",
    "    if 'AMT_ANNUITY' in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n",
    "        data['ANNUITY_TO_INCOME_RATIO'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    # Fill any NaNs created by division\n",
    "    for col in data.columns:\n",
    "        if col not in cols_to_drop + ['TARGET']:\n",
    "            data[col] = data[col].replace([np.inf, -np.inf], np.nan)\n",
    "            data[col] = data[col].fillna(0)\n",
    "    \n",
    "    print(f\"Preprocessing complete. Data shape: {data.shape}\")\n",
    "    return data\n",
    "\n",
    "# Preprocess training data\n",
    "train_processed = preprocess_main_data(train_with_preds, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d345e851-b3d4-4cd0-9e8e-07436f9df7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training main model with cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13354\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432482\n",
      "[LightGBM] [Info] Start training from score -2.432482\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's auc: 0.802885\tvalid_0's binary_logloss: 0.230665\n",
      "Fold 1 AUC: 0.8029\n",
      "\n",
      "Fold 2/5\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13437\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 125\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's auc: 0.811027\tvalid_0's binary_logloss: 0.227808\n",
      "Fold 2 AUC: 0.8110\n",
      "\n",
      "Fold 3/5\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13343\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[481]\tvalid_0's auc: 0.798051\tvalid_0's binary_logloss: 0.232935\n",
      "Fold 3 AUC: 0.7981\n",
      "\n",
      "Fold 4/5\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13349\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[383]\tvalid_0's auc: 0.805106\tvalid_0's binary_logloss: 0.229541\n",
      "Fold 4 AUC: 0.8051\n",
      "\n",
      "Fold 5/5\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13344\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[354]\tvalid_0's auc: 0.801086\tvalid_0's binary_logloss: 0.23189\n",
      "Fold 5 AUC: 0.8011\n",
      "\n",
      "Cross-validation AUC: 0.8036 ± 0.0044\n",
      "Out-of-fold AUC: 0.8036\n",
      "\n",
      "Top 20 important features:\n",
      "                        feature  importance\n",
      "48                 EXT_SOURCE_3       560.0\n",
      "47                 EXT_SOURCE_2       520.8\n",
      "46                 EXT_SOURCE_1       511.4\n",
      "18                APP_PRED_MEAN       483.8\n",
      "19                 APP_PRED_MIN       427.6\n",
      "35       DAYS_LAST_PHONE_CHANGE       406.2\n",
      "1                   AMT_ANNUITY       370.0\n",
      "2                    AMT_CREDIT       348.4\n",
      "34              DAYS_ID_PUBLISH       345.0\n",
      "17                 APP_PRED_MAX       330.8\n",
      "32                   DAYS_BIRTH       313.0\n",
      "33                DAYS_EMPLOYED       303.8\n",
      "36            DAYS_REGISTRATION       288.2\n",
      "11      ANNUITY_TO_INCOME_RATIO       268.4\n",
      "114  REGION_POPULATION_RELATIVE       251.0\n",
      "0                     AGE_YEARS       250.2\n",
      "3               AMT_GOODS_PRICE       244.8\n",
      "20               APP_PRED_RANGE       238.8\n",
      "31       CREDIT_TO_INCOME_RATIO       228.2\n",
      "4              AMT_INCOME_TOTAL       208.6\n",
      "\n",
      "Ranking of application-level prediction features:\n",
      "Rank 19: APP_PRED_MEAN - Importance: 483.8\n",
      "Rank 20: APP_PRED_MIN - Importance: 427.6\n",
      "Rank 18: APP_PRED_MAX - Importance: 330.8\n",
      "Rank 21: APP_PRED_RANGE - Importance: 238.8\n",
      "Rank 22: APP_PRED_STD - Importance: 192.6\n",
      "Rank 16: APP_PRED_COUNT - Importance: 142.6\n",
      "Rank 17: APP_PRED_COUNT_NORM - Importance: 30.6\n"
     ]
    }
   ],
   "source": [
    "def train_main_model_cv(train_data, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Train the main model (Stage 2) with cross-validation\n",
    "    \"\"\"\n",
    "    print(\"Training main model with cross-validation...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = train_data.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "    y = train_data['TARGET']\n",
    "    \n",
    "    # Initialize LightGBM classifier\n",
    "    model = lgbm.LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=32,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_weight=2,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Initialize cross-validation\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Lists to store results\n",
    "    cv_scores = []\n",
    "    feature_importance_dfs = []\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    \n",
    "    # Cross-validation loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Train the model with early stopping\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='auc',\n",
    "            callbacks=[lgbm.early_stopping(stopping_rounds=100, verbose=True)]\n",
    "        )\n",
    "        \n",
    "        # Predict on validation set\n",
    "        val_preds = model.predict_proba(X_val)[:, 1]\n",
    "        oof_preds[val_idx] = val_preds\n",
    "        \n",
    "        # Calculate AUC\n",
    "        auc = roc_auc_score(y_val, val_preds)\n",
    "        cv_scores.append(auc)\n",
    "        print(f\"Fold {fold + 1} AUC: {auc:.4f}\")\n",
    "        \n",
    "        # Store feature importance\n",
    "        fold_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': model.feature_importances_\n",
    "        })\n",
    "        fold_importance['fold'] = fold + 1\n",
    "        feature_importance_dfs.append(fold_importance)\n",
    "    \n",
    "    # Calculate overall CV score\n",
    "    cv_score_mean = np.mean(cv_scores)\n",
    "    cv_score_std = np.std(cv_scores)\n",
    "    print(f\"\\nCross-validation AUC: {cv_score_mean:.4f} ± {cv_score_std:.4f}\")\n",
    "    \n",
    "    # Calculate overall AUC on out-of-fold predictions\n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"Out-of-fold AUC: {oof_auc:.4f}\")\n",
    "    \n",
    "    # Combine feature importances from all folds\n",
    "    feature_importance = pd.concat(feature_importance_dfs)\n",
    "    feature_importance_mean = feature_importance.groupby('feature')['importance'].mean().reset_index()\n",
    "    feature_importance_mean = feature_importance_mean.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 important features:\")\n",
    "    print(feature_importance_mean.head(20))\n",
    "    \n",
    "    # Check the rank of our new application-level prediction features\n",
    "    app_pred_features = [col for col in X.columns if col.startswith('APP_PRED_')]\n",
    "    app_pred_importance = feature_importance_mean[feature_importance_mean['feature'].isin(app_pred_features)]\n",
    "    print(\"\\nRanking of application-level prediction features:\")\n",
    "    for i, row in app_pred_importance.iterrows():\n",
    "        print(f\"Rank {feature_importance_mean[feature_importance_mean['feature'] == row['feature']].index[0] + 1}: {row['feature']} - Importance: {row['importance']}\")\n",
    "    \n",
    "    return model, feature_importance_mean, oof_preds, oof_auc\n",
    "\n",
    "# Train main model with cross-validation\n",
    "main_model, feature_importance, oof_preds, oof_auc = train_main_model_cv(train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cc35f8a-e3ff-4aba-aedb-c4e279887e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing test data with application-level predictions...\n",
      "Previous applications for test customers: (256513, 37)\n",
      "Preprocessing application-level features...\n",
      "Preprocessing complete. Data shape: (256513, 42)\n",
      "Aggregating application-level predictions by customer...\n",
      "Aggregated predictions shape: (47800, 8)\n",
      "\n",
      "Sample of aggregated predictions:\n",
      "       SK_ID_CURR  APP_PRED_MEAN  APP_PRED_MAX  APP_PRED_MIN  APP_PRED_STD  \\\n",
      "43317      422796       0.096354      0.106559      0.086150      0.014432   \n",
      "16423      220949       0.069017      0.085832      0.042140      0.016536   \n",
      "32066      338174       0.067087      0.170206      0.039867      0.034702   \n",
      "14046      203176       0.081933      0.101858      0.070103      0.017356   \n",
      "43936      428143       0.121032      0.192098      0.070576      0.046701   \n",
      "\n",
      "       APP_PRED_COUNT  APP_PRED_RANGE  APP_PRED_COUNT_NORM  \n",
      "43317               2        0.020409             1.098612  \n",
      "16423               6        0.043692             1.945910  \n",
      "32066              12        0.130339             2.564949  \n",
      "14046               3        0.031755             1.386294  \n",
      "43936               6        0.121522             1.945910  \n",
      "Preprocessing test data...\n",
      "Preprocessing complete. Data shape: (48744, 131)\n"
     ]
    }
   ],
   "source": [
    "def prepare_test_data():\n",
    "    \"\"\"\n",
    "    Prepare test data with application-level predictions\n",
    "    \"\"\"\n",
    "    print(\"Preparing test data with application-level predictions...\")\n",
    "    \n",
    "    # Load previous applications for test customers\n",
    "    test_prev_apps = prev_df[prev_df['SK_ID_CURR'].isin(test_df['SK_ID_CURR'])]\n",
    "    print(f\"Previous applications for test customers: {test_prev_apps.shape}\")\n",
    "    \n",
    "    # Preprocess these applications (same as we did for training)\n",
    "    test_prev_features = preprocess_app_level_features(test_prev_apps)\n",
    "    \n",
    "    # Use our application-level model to generate predictions\n",
    "    X_test_prev = test_prev_features.drop(['SK_ID_CURR', 'SK_ID_PREV', 'TARGET'], axis=1, errors='ignore')\n",
    "    \n",
    "    # Make sure X_test_prev has the same columns as the training data\n",
    "    missing_cols = set(app_level_model.feature_name_) - set(X_test_prev.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test_prev[col] = 0  # Add missing columns with default values\n",
    "    \n",
    "    # Use only the columns that were used during training\n",
    "    X_test_prev = X_test_prev[app_level_model.feature_name_]\n",
    "    \n",
    "    # Generate predictions\n",
    "    test_prev_preds = app_level_model.predict_proba(X_test_prev)[:, 1]\n",
    "    \n",
    "    # Add predictions back to the dataframe\n",
    "    test_app_preds = test_prev_features[['SK_ID_CURR', 'SK_ID_PREV']].copy()\n",
    "    test_app_preds['APP_PRED'] = test_prev_preds\n",
    "    \n",
    "    # Aggregate predictions by customer\n",
    "    test_agg_preds = aggregate_app_predictions(test_app_preds)\n",
    "    \n",
    "    # Add aggregated predictions to test data\n",
    "    test_with_preds = test_df.merge(test_agg_preds, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    # Fill missing values for customers with no previous applications\n",
    "    for col in ['APP_PRED_MEAN', 'APP_PRED_MAX', 'APP_PRED_MIN']:\n",
    "        test_with_preds[col] = test_with_preds[col].fillna(0.5)\n",
    "    \n",
    "    test_with_preds['APP_PRED_STD'] = test_with_preds['APP_PRED_STD'].fillna(0)\n",
    "    test_with_preds['APP_PRED_RANGE'] = test_with_preds['APP_PRED_RANGE'].fillna(0)\n",
    "    test_with_preds['APP_PRED_COUNT'] = test_with_preds['APP_PRED_COUNT'].fillna(0)\n",
    "    test_with_preds['APP_PRED_COUNT_NORM'] = test_with_preds['APP_PRED_COUNT_NORM'].fillna(0)\n",
    "    \n",
    "    # Preprocess the test data\n",
    "    test_processed = preprocess_main_data(test_with_preds, is_training=False)\n",
    "    \n",
    "    return test_processed, test_with_preds['SK_ID_CURR']\n",
    "\n",
    "# Prepare test data\n",
    "test_processed, test_ids = prepare_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e48c7d0-c81c-435d-ad01-4617765b47bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model and generating predictions...\n",
      "[LightGBM] [Info] Number of positive: 24825, number of negative: 282686\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13448\n",
      "[LightGBM] [Info] Number of data points in the train set: 307511, number of used features: 126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Submission saved to /Users/braidosan/Downloads/home-credit-default-risk/submission_two_stage.csv\n",
      "Submission predictions range: 0.001133585423086148 to 0.8510268314150462\n"
     ]
    }
   ],
   "source": [
    "def train_final_model_and_predict(train_data, test_data, test_ids):\n",
    "    \"\"\"\n",
    "    Train a final model on all training data and make predictions on test data\n",
    "    \"\"\"\n",
    "    print(\"Training final model and generating predictions...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_train = train_data.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "    y_train = train_data['TARGET']\n",
    "    \n",
    "    # Make sure test data has the same columns as training data\n",
    "    missing_cols = set(X_train.columns) - set(test_data.columns)\n",
    "    for col in missing_cols:\n",
    "        test_data[col] = 0  # Add missing columns with default values\n",
    "        \n",
    "    # Use only the columns that exist in training data\n",
    "    X_test = test_data[X_train.columns]\n",
    "    \n",
    "    # Initialize LightGBM classifier with the parameters that worked well in CV\n",
    "    final_model = lgbm.LGBMClassifier(\n",
    "        n_estimators=500,  # We'll use a fixed number based on the average from CV\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=32,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_weight=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model on all training data\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions on test data\n",
    "    test_preds = final_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission = pd.DataFrame({\n",
    "        'SK_ID_CURR': test_ids,\n",
    "        'TARGET': test_preds\n",
    "    })\n",
    "    \n",
    "    # Save submission to CSV\n",
    "    submission_path = os.path.join(DATA_DIR, \"submission_two_stage.csv\")\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(f\"Submission saved to {submission_path}\")\n",
    "    print(f\"Submission predictions range: {submission['TARGET'].min()} to {submission['TARGET'].max()}\")\n",
    "    \n",
    "    return submission, final_model\n",
    "\n",
    "# Train final model and generate predictions\n",
    "submission, final_model = train_final_model_and_predict(train_processed, test_processed, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "000345b2-6c25-44a8-8b3d-e90a8baf3a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version 'two_stage_v1' saved successfully\n"
     ]
    }
   ],
   "source": [
    "# At the end of your current notebook, save the current results\n",
    "import pickle\n",
    "\n",
    "# Create a results directory if it doesn't exist\n",
    "results_dir = os.path.join(DATA_DIR, 'model_versions')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save version information\n",
    "version_info = {\n",
    "    'version': 'two_stage_v1',\n",
    "    'cv_auc': 0.8036,\n",
    "    'cv_std': 0.0044,\n",
    "    'feature_importance': feature_importance,\n",
    "    'description': 'Two-stage model with application-level predictions'\n",
    "}\n",
    "\n",
    "# Save models and results\n",
    "with open(os.path.join(results_dir, 'two_stage_v1_app_level_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(app_level_model, f)\n",
    "\n",
    "with open(os.path.join(results_dir, 'two_stage_v1_final_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "    \n",
    "with open(os.path.join(results_dir, 'two_stage_v1_info.pkl'), 'wb') as f:\n",
    "    pickle.dump(version_info, f)\n",
    "\n",
    "# Save a copy of the submission with version number\n",
    "submission.to_csv(os.path.join(results_dir, 'submission_two_stage_v1.csv'), index=False)\n",
    "\n",
    "print(\"Model version 'two_stage_v1' saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef2ffbe0-2344-4d1d-8b72-35ea2dc48411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bureau data...\n",
      "Loading bureau data...\n",
      "Bureau shape: (1716428, 17), Bureau balance shape: (27299925, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load bureau data\n",
    "print(\"Loading bureau data...\")\n",
    "bureau_df, bureau_balance = load_bureau_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1088d39-deed-440e-9adb-564cd3eb5d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing bureau-level data...\n",
      "Bureau-level data ready: (1465325, 18)\n",
      "TARGET distribution at bureau level:\n",
      "TARGET\n",
      "0    0.921847\n",
      "1    0.078153\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sample of bureau-level data:\n",
      "         SK_ID_CURR  SK_ID_BUREAU  TARGET  DAYS_CREDIT  AMT_CREDIT_SUM\n",
      "1437550      160066       5399728       0         -594       3015000.0\n",
      "983321       432057       5073254       0        -2874         92700.0\n",
      "1585205      230562       5583191       0         -182        135000.0\n",
      "265532       438166       5890410       0        -1618        124519.5\n",
      "565991       247996       5692855       0        -2626        202500.0\n"
     ]
    }
   ],
   "source": [
    "def prepare_bureau_level_data():\n",
    "    \"\"\"\n",
    "    Prepare data at the bureau record level with TARGET from main application\n",
    "    \"\"\"\n",
    "    print(\"Preparing bureau-level data...\")\n",
    "    \n",
    "    # Get mapping from SK_ID_CURR to TARGET\n",
    "    target_mapping = train_df[['SK_ID_CURR', 'TARGET']].set_index('SK_ID_CURR')['TARGET'].to_dict()\n",
    "    \n",
    "    # Start with bureau data\n",
    "    bureau_data = bureau_df.copy()\n",
    "    \n",
    "    # Filter to keep only records from customers in the training set\n",
    "    bureau_data = bureau_data[bureau_data['SK_ID_CURR'].isin(train_df['SK_ID_CURR'])]\n",
    "    \n",
    "    # Add TARGET to each bureau record\n",
    "    bureau_data['TARGET'] = bureau_data['SK_ID_CURR'].map(target_mapping)\n",
    "    \n",
    "    # Check for any missing targets\n",
    "    missing_target = bureau_data['TARGET'].isnull().sum()\n",
    "    if missing_target > 0:\n",
    "        print(f\"Warning: {missing_target} bureau records have missing TARGET values\")\n",
    "        # Drop rows with missing TARGET\n",
    "        bureau_data = bureau_data.dropna(subset=['TARGET'])\n",
    "    \n",
    "    print(f\"Bureau-level data ready: {bureau_data.shape}\")\n",
    "    \n",
    "    # Display distribution of TARGET at bureau level\n",
    "    target_dist = bureau_data['TARGET'].value_counts(normalize=True)\n",
    "    print(f\"TARGET distribution at bureau level:\\n{target_dist}\")\n",
    "    \n",
    "    return bureau_data\n",
    "\n",
    "# Prepare bureau-level data\n",
    "bureau_level_data = prepare_bureau_level_data()\n",
    "\n",
    "# Display a sample of the data\n",
    "print(\"\\nSample of bureau-level data:\")\n",
    "print(bureau_level_data.sample(5)[['SK_ID_CURR', 'SK_ID_BUREAU', 'TARGET', 'DAYS_CREDIT', 'AMT_CREDIT_SUM']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44a46186-71e3-45fe-810d-f467551f3607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing bureau-level features...\n",
      "Added bureau balance features\n",
      "Preprocessing complete. Data shape: (1465325, 27)\n",
      "\n",
      "Feature information:\n",
      "Number of features: 24\n"
     ]
    }
   ],
   "source": [
    "def preprocess_bureau_level_features(bureau_data):\n",
    "    \"\"\"\n",
    "    Preprocess features for the bureau-level model\n",
    "    \"\"\"\n",
    "    print(\"Preprocessing bureau-level features...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = bureau_data.copy()\n",
    "    \n",
    "    # Add aggregated bureau balance features if needed\n",
    "    # This is optional but can add valuable information\n",
    "    try:\n",
    "        # Group bureau balance by SK_ID_BUREAU\n",
    "        bureau_balance_agg = bureau_balance.groupby('SK_ID_BUREAU').agg({\n",
    "            'MONTHS_BALANCE': ['min', 'max', 'mean', 'size'],\n",
    "            'STATUS': lambda x: x.value_counts().get('C', 0)  # Count of 'C' (closed) statuses\n",
    "        })\n",
    "        \n",
    "        # Flatten column names\n",
    "        bureau_balance_agg.columns = ['BB_' + '_'.join(col).upper() for col in bureau_balance_agg.columns]\n",
    "        bureau_balance_agg = bureau_balance_agg.reset_index()\n",
    "        \n",
    "        # Merge with bureau data\n",
    "        df = df.merge(bureau_balance_agg, on='SK_ID_BUREAU', how='left')\n",
    "        print(\"Added bureau balance features\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding bureau balance features: {e}\")\n",
    "    \n",
    "    # Handle missing values\n",
    "    for col in df.columns:\n",
    "        # Skip ID columns and TARGET\n",
    "        if col in ['SK_ID_CURR', 'SK_ID_BUREAU', 'TARGET']:\n",
    "            continue\n",
    "            \n",
    "        # Fill categorical missing values with 'Missing'\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna('Missing')\n",
    "            \n",
    "            # Label encode categorical columns\n",
    "            lbe = LabelEncoder()\n",
    "            df[col] = lbe.fit_transform(df[col])\n",
    "        else:\n",
    "            # Fill numerical missing values with median\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    # Create additional features from DAYS_CREDIT\n",
    "    df['DAYS_CREDIT_ABS'] = np.abs(df['DAYS_CREDIT'])  # Absolute value\n",
    "    df['DAYS_CREDIT_RECENT'] = np.exp(df['DAYS_CREDIT'] / 365)  # Emphasize recent credits\n",
    "    \n",
    "    # Calculate credit utilization if possible\n",
    "    if 'AMT_CREDIT_SUM' in df.columns and 'AMT_CREDIT_SUM_LIMIT' in df.columns:\n",
    "        df['CREDIT_UTILIZATION'] = df['AMT_CREDIT_SUM'] / df['AMT_CREDIT_SUM_LIMIT'].replace(0, np.nan)\n",
    "        df['CREDIT_UTILIZATION'] = df['CREDIT_UTILIZATION'].fillna(1)  # Assume 100% utilization when limit is 0\n",
    "        df['CREDIT_UTILIZATION'] = df['CREDIT_UTILIZATION'].clip(0, 1)  # Clip between 0 and 1\n",
    "    \n",
    "    # Calculate overdue ratio if possible\n",
    "    if 'AMT_CREDIT_SUM_OVERDUE' in df.columns and 'AMT_CREDIT_SUM' in df.columns:\n",
    "        df['OVERDUE_RATIO'] = df['AMT_CREDIT_SUM_OVERDUE'] / df['AMT_CREDIT_SUM'].replace(0, np.nan)\n",
    "        df['OVERDUE_RATIO'] = df['OVERDUE_RATIO'].fillna(0)\n",
    "        df['OVERDUE_RATIO'] = df['OVERDUE_RATIO'].clip(0, 1)  # Clip between 0 and 1\n",
    "    \n",
    "    # Fill NaN from division with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    print(f\"Preprocessing complete. Data shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# Preprocess bureau-level features\n",
    "bureau_level_features = preprocess_bureau_level_features(bureau_level_data)\n",
    "\n",
    "# Display feature information\n",
    "print(\"\\nFeature information:\")\n",
    "print(f\"Number of features: {bureau_level_features.shape[1] - 3}\")  # Exclude SK_ID_CURR, SK_ID_BUREAU, TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7664709b-d163-4d4a-860b-8a863a54a514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bureau-level model...\n",
      "[LightGBM] [Info] Number of positive: 91616, number of negative: 1080644\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4087\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172260, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078153 -> initscore=-2.467707\n",
      "[LightGBM] [Info] Start training from score -2.467707\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's auc: 0.612387\tvalid_0's binary_logloss: 0.267719\n",
      "\n",
      "Bureau-level model validation AUC: 0.6124\n",
      "\n",
      "Top 20 important features:\n",
      "                   feature  importance\n",
      "8           AMT_CREDIT_SUM        3911\n",
      "13      DAYS_CREDIT_UPDATE        3651\n",
      "4      DAYS_CREDIT_ENDDATE        3456\n",
      "9      AMT_CREDIT_SUM_DEBT        2203\n",
      "2              DAYS_CREDIT        2112\n",
      "5        DAYS_ENDDATE_FACT        1974\n",
      "14             AMT_ANNUITY        1971\n",
      "20         DAYS_CREDIT_ABS        1680\n",
      "18  BB_MONTHS_BALANCE_SIZE        1613\n",
      "19      BB_STATUS_<LAMBDA>        1308\n",
      "6   AMT_CREDIT_MAX_OVERDUE        1173\n",
      "17  BB_MONTHS_BALANCE_MEAN        1150\n",
      "10    AMT_CREDIT_SUM_LIMIT         793\n",
      "16   BB_MONTHS_BALANCE_MAX         791\n",
      "15   BB_MONTHS_BALANCE_MIN         717\n",
      "21      DAYS_CREDIT_RECENT         684\n",
      "12             CREDIT_TYPE         628\n",
      "11  AMT_CREDIT_SUM_OVERDUE         224\n",
      "3       CREDIT_DAY_OVERDUE         224\n",
      "23           OVERDUE_RATIO         195\n"
     ]
    }
   ],
   "source": [
    "def train_bureau_level_model(bureau_level_features, random_state=42):\n",
    "    \"\"\"\n",
    "    Train the bureau-level model (Stage 1 for bureau data)\n",
    "    \"\"\"\n",
    "    print(\"Training bureau-level model...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    features = bureau_level_features.drop(['SK_ID_CURR', 'SK_ID_BUREAU', 'TARGET'], axis=1)\n",
    "    target = bureau_level_features['TARGET']\n",
    "    \n",
    "    # Split data for validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        features, target, test_size=0.2, random_state=random_state, stratify=target\n",
    "    )\n",
    "    \n",
    "    # Define the LightGBM model\n",
    "    model = lgbm.LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=32,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_weight=2,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgbm.early_stopping(stopping_rounds=100, verbose=True)]\n",
    "    )\n",
    "    \n",
    "    # Generate predictions for all bureau records\n",
    "    all_predictions = model.predict_proba(features)[:, 1]\n",
    "    \n",
    "    # Add predictions back to the dataframe\n",
    "    bureau_level_preds = bureau_level_features[['SK_ID_CURR', 'SK_ID_BUREAU']].copy()\n",
    "    bureau_level_preds['BUREAU_PRED'] = all_predictions\n",
    "    \n",
    "    # Show model performance\n",
    "    val_preds = model.predict_proba(X_val)[:, 1]\n",
    "    val_auc = roc_auc_score(y_val, val_preds)\n",
    "    print(f\"\\nBureau-level model validation AUC: {val_auc:.4f}\")\n",
    "    \n",
    "    # Show feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 important features:\")\n",
    "    print(feature_importance.head(20))\n",
    "    \n",
    "    return bureau_level_preds, model\n",
    "\n",
    "# Train bureau-level model\n",
    "bureau_level_preds, bureau_level_model = train_bureau_level_model(bureau_level_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90230541-23fb-44a9-b49c-05093b4c0a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating bureau-level predictions by customer...\n",
      "Aggregated bureau predictions shape: (263491, 8)\n",
      "\n",
      "Sample of aggregated bureau predictions:\n",
      "        SK_ID_CURR  BUREAU_PRED_MEAN  BUREAU_PRED_MAX  BUREAU_PRED_MIN  \\\n",
      "232660      414753          0.091543         0.091543         0.091543   \n",
      "138390      287020          0.065243         0.072053         0.055617   \n",
      "232518      414558          0.074000         0.097013         0.062533   \n",
      "170807      331043          0.084672         0.088410         0.080934   \n",
      "218851      395579          0.101481         0.123154         0.079807   \n",
      "\n",
      "        BUREAU_PRED_STD  BUREAU_PRED_COUNT  BUREAU_PRED_RANGE  \\\n",
      "232660         0.000000                  1           0.000000   \n",
      "138390         0.005098                  9           0.016436   \n",
      "232518         0.016251                  4           0.034480   \n",
      "170807         0.005286                  2           0.007475   \n",
      "218851         0.030651                  2           0.043346   \n",
      "\n",
      "        BUREAU_PRED_COUNT_NORM  \n",
      "232660                0.693147  \n",
      "138390                2.302585  \n",
      "232518                1.609438  \n",
      "170807                1.098612  \n",
      "218851                1.098612  \n"
     ]
    }
   ],
   "source": [
    "def aggregate_bureau_predictions(bureau_level_preds):\n",
    "    \"\"\"\n",
    "    Aggregate bureau-level predictions by customer\n",
    "    \"\"\"\n",
    "    print(\"Aggregating bureau-level predictions by customer...\")\n",
    "    \n",
    "    # Group by customer ID and calculate statistics of the predictions\n",
    "    agg_preds = bureau_level_preds.groupby('SK_ID_CURR').agg({\n",
    "        'BUREAU_PRED': ['mean', 'max', 'min', 'std', 'count']\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    agg_preds.columns = ['BUREAU_PRED_' + col for col in ['MEAN', 'MAX', 'MIN', 'STD', 'COUNT']]\n",
    "    \n",
    "    # Reset index\n",
    "    agg_preds = agg_preds.reset_index()\n",
    "    \n",
    "    # Handle missing std values (customers with only one bureau record)\n",
    "    agg_preds['BUREAU_PRED_STD'] = agg_preds['BUREAU_PRED_STD'].fillna(0)\n",
    "    \n",
    "    # Add range feature\n",
    "    agg_preds['BUREAU_PRED_RANGE'] = agg_preds['BUREAU_PRED_MAX'] - agg_preds['BUREAU_PRED_MIN']\n",
    "    \n",
    "    # Add normalized count (log transform to handle skewness)\n",
    "    agg_preds['BUREAU_PRED_COUNT_NORM'] = np.log1p(agg_preds['BUREAU_PRED_COUNT'])\n",
    "    \n",
    "    print(f\"Aggregated bureau predictions shape: {agg_preds.shape}\")\n",
    "    \n",
    "    # Display sample of aggregated predictions\n",
    "    print(\"\\nSample of aggregated bureau predictions:\")\n",
    "    print(agg_preds.sample(5))\n",
    "    \n",
    "    return agg_preds\n",
    "\n",
    "# Aggregate bureau-level predictions\n",
    "bureau_agg_preds = aggregate_bureau_predictions(bureau_level_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5eecab40-4752-49ae-b551-d295699ab158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding bureau predictions to training data...\n",
      "Customers with bureau records: 263491 (85.69%)\n",
      "Training data with bureau predictions shape: (307511, 136)\n"
     ]
    }
   ],
   "source": [
    "def add_bureau_preds_to_train(train_with_preds, bureau_agg_preds):\n",
    "    \"\"\"\n",
    "    Add aggregated bureau predictions to training data\n",
    "    \"\"\"\n",
    "    print(\"Adding bureau predictions to training data...\")\n",
    "    \n",
    "    # Make a copy of the training data\n",
    "    train_with_bureau = train_with_preds.copy()\n",
    "    \n",
    "    # Merge with bureau predictions\n",
    "    train_with_bureau = train_with_bureau.merge(bureau_agg_preds, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    # Fill missing values for customers with no bureau records\n",
    "    for col in bureau_agg_preds.columns:\n",
    "        if col == 'SK_ID_CURR':\n",
    "            continue\n",
    "            \n",
    "        if col in ['BUREAU_PRED_MEAN', 'BUREAU_PRED_MAX', 'BUREAU_PRED_MIN']:\n",
    "            # For customers with no bureau records, use a default value\n",
    "            train_with_bureau[col] = train_with_bureau[col].fillna(0.5)\n",
    "        elif col in ['BUREAU_PRED_STD', 'BUREAU_PRED_RANGE']:\n",
    "            train_with_bureau[col] = train_with_bureau[col].fillna(0)\n",
    "        elif col in ['BUREAU_PRED_COUNT', 'BUREAU_PRED_COUNT_NORM']:\n",
    "            train_with_bureau[col] = train_with_bureau[col].fillna(0)\n",
    "    \n",
    "    # Check how many customers have bureau records\n",
    "    has_bureau = train_with_bureau['BUREAU_PRED_COUNT'] > 0\n",
    "    print(f\"Customers with bureau records: {has_bureau.sum()} ({has_bureau.mean()*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"Training data with bureau predictions shape: {train_with_bureau.shape}\")\n",
    "    return train_with_bureau\n",
    "\n",
    "# Add bureau predictions to training data\n",
    "train_with_bureau = add_bureau_preds_to_train(train_with_preds, bureau_agg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a18bfc75-ca8a-4888-96b2-42c43fea7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing test data with bureau-level predictions...\n",
      "Bureau records for test customers: (251103, 17)\n",
      "Preprocessing bureau-level features...\n",
      "Added bureau balance features\n",
      "Preprocessing complete. Data shape: (251103, 26)\n",
      "Aggregating bureau-level predictions by customer...\n",
      "Aggregated bureau predictions shape: (42320, 8)\n",
      "\n",
      "Sample of aggregated bureau predictions:\n",
      "       SK_ID_CURR  BUREAU_PRED_MEAN  BUREAU_PRED_MAX  BUREAU_PRED_MIN  \\\n",
      "35667      401983          0.104564         0.127262         0.081866   \n",
      "30377      355588          0.064478         0.067221         0.061736   \n",
      "24627      306848          0.071694         0.071694         0.071694   \n",
      "30843      359847          0.072727         0.127005         0.041916   \n",
      "15669      230553          0.061021         0.076853         0.046370   \n",
      "\n",
      "       BUREAU_PRED_STD  BUREAU_PRED_COUNT  BUREAU_PRED_RANGE  \\\n",
      "35667         0.032100                  2           0.045396   \n",
      "30377         0.003878                  2           0.005485   \n",
      "24627         0.000000                  1           0.000000   \n",
      "30843         0.025784                 10           0.085088   \n",
      "15669         0.010855                  7           0.030483   \n",
      "\n",
      "       BUREAU_PRED_COUNT_NORM  \n",
      "35667                1.098612  \n",
      "30377                1.098612  \n",
      "24627                0.693147  \n",
      "30843                2.397895  \n",
      "15669                2.079442  \n",
      "Test data with bureau predictions shape: (48744, 128)\n"
     ]
    }
   ],
   "source": [
    "def prepare_test_bureau_data():\n",
    "    \"\"\"\n",
    "    Prepare test data with bureau-level predictions\n",
    "    \"\"\"\n",
    "    print(\"Preparing test data with bureau-level predictions...\")\n",
    "    \n",
    "    # Load bureau data for test customers if not already done\n",
    "    test_bureau = bureau_df[bureau_df['SK_ID_CURR'].isin(test_df['SK_ID_CURR'])]\n",
    "    print(f\"Bureau records for test customers: {test_bureau.shape}\")\n",
    "    \n",
    "    # Preprocess these bureau records (same as we did for training)\n",
    "    test_bureau_features = preprocess_bureau_level_features(test_bureau)\n",
    "    \n",
    "    # Use our bureau-level model to generate predictions\n",
    "    X_test_bureau = test_bureau_features.drop(['SK_ID_CURR', 'SK_ID_BUREAU'], axis=1, errors='ignore')\n",
    "    if 'TARGET' in X_test_bureau.columns:\n",
    "        X_test_bureau = X_test_bureau.drop('TARGET', axis=1)\n",
    "    \n",
    "    # Make sure X_test_bureau has the same columns as the training data\n",
    "    missing_cols = set(bureau_level_model.feature_name_) - set(X_test_bureau.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test_bureau[col] = 0  # Add missing columns with default values\n",
    "    \n",
    "    # Use only the columns that were used during training\n",
    "    X_test_bureau = X_test_bureau[bureau_level_model.feature_name_]\n",
    "    \n",
    "    # Generate predictions\n",
    "    test_bureau_preds = bureau_level_model.predict_proba(X_test_bureau)[:, 1]\n",
    "    \n",
    "    # Add predictions back to the dataframe\n",
    "    test_bureau_preds_df = test_bureau_features[['SK_ID_CURR', 'SK_ID_BUREAU']].copy()\n",
    "    test_bureau_preds_df['BUREAU_PRED'] = test_bureau_preds\n",
    "    \n",
    "    # Aggregate predictions by customer\n",
    "    test_bureau_agg = aggregate_bureau_predictions(test_bureau_preds_df)\n",
    "    \n",
    "    # Merge with test data\n",
    "    # Fix: use test_df instead of test_with_preds\n",
    "    test_with_bureau = test_df.copy()\n",
    "    test_with_bureau = test_with_bureau.merge(test_bureau_agg, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    # Fill missing values for customers with no bureau records\n",
    "    for col in test_bureau_agg.columns:\n",
    "        if col == 'SK_ID_CURR':\n",
    "            continue\n",
    "            \n",
    "        if col in ['BUREAU_PRED_MEAN', 'BUREAU_PRED_MAX', 'BUREAU_PRED_MIN']:\n",
    "            test_with_bureau[col] = test_with_bureau[col].fillna(0.5)\n",
    "        elif col in ['BUREAU_PRED_STD', 'BUREAU_PRED_RANGE']:\n",
    "            test_with_bureau[col] = test_with_bureau[col].fillna(0)\n",
    "        elif col in ['BUREAU_PRED_COUNT', 'BUREAU_PRED_COUNT_NORM']:\n",
    "            test_with_bureau[col] = test_with_bureau[col].fillna(0)\n",
    "    \n",
    "    print(f\"Test data with bureau predictions shape: {test_with_bureau.shape}\")\n",
    "    return test_with_bureau\n",
    "\n",
    "# Prepare test data with bureau predictions\n",
    "test_with_bureau = prepare_test_bureau_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61274ea8-b992-4476-93cc-3e0ddea2b642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing enhanced training data...\n",
      "Enhanced preprocessing complete. Data shape: (307511, 142)\n",
      "Preprocessing enhanced test data...\n",
      "Enhanced preprocessing complete. Data shape: (48744, 131)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_enhanced_data(df, is_training=True):\n",
    "    \"\"\"\n",
    "    Preprocess the enhanced dataset (with both app and bureau predictions)\n",
    "    \"\"\"\n",
    "    print(f\"Preprocessing enhanced {'training' if is_training else 'test'} data...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying original data\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Define columns to drop\n",
    "    cols_to_drop = ['SK_ID_CURR']\n",
    "    if is_training:\n",
    "        # TARGET is not dropped from training data\n",
    "        pass\n",
    "    \n",
    "    # Handle missing values in numerical columns\n",
    "    num_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in num_cols:\n",
    "        # Skip TARGET and identifier columns\n",
    "        if col in ['TARGET', 'SK_ID_CURR']:\n",
    "            continue\n",
    "            \n",
    "        # Replace infinity values with NaN\n",
    "        data[col] = data[col].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Fill NaN with median\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "    \n",
    "    # Handle categorical columns\n",
    "    cat_cols = data.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        # Fill missing with 'Unknown'\n",
    "        data[col] = data[col].fillna('Unknown')\n",
    "        \n",
    "        # Label encode categorical variables\n",
    "        if col not in cols_to_drop:\n",
    "            le = LabelEncoder()\n",
    "            data[col] = le.fit_transform(data[col])\n",
    "    \n",
    "    # Create some additional features\n",
    "    \n",
    "    # Age in years (negative because DAYS_BIRTH is negative)\n",
    "    if 'DAYS_BIRTH' in data.columns:\n",
    "        data['AGE_YEARS'] = -data['DAYS_BIRTH'] / 365\n",
    "    \n",
    "    # Credit to income ratio\n",
    "    if 'AMT_CREDIT' in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n",
    "        data['CREDIT_TO_INCOME_RATIO'] = data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    # Annuity to income ratio\n",
    "    if 'AMT_ANNUITY' in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n",
    "        data['ANNUITY_TO_INCOME_RATIO'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    # Create interaction features between app and bureau predictions\n",
    "    if 'APP_PRED_MEAN' in data.columns and 'BUREAU_PRED_MEAN' in data.columns:\n",
    "        data['APP_X_BUREAU_MEAN'] = data['APP_PRED_MEAN'] * data['BUREAU_PRED_MEAN']\n",
    "        data['APP_X_BUREAU_MAX'] = data['APP_PRED_MAX'] * data['BUREAU_PRED_MAX']\n",
    "        data['APP_X_BUREAU_MIN'] = data['APP_PRED_MIN'] * data['BUREAU_PRED_MIN']\n",
    "    \n",
    "    # Fill any NaNs created by division\n",
    "    for col in data.columns:\n",
    "        if col not in cols_to_drop + ['TARGET']:\n",
    "            data[col] = data[col].replace([np.inf, -np.inf], np.nan)\n",
    "            data[col] = data[col].fillna(0)\n",
    "    \n",
    "    print(f\"Enhanced preprocessing complete. Data shape: {data.shape}\")\n",
    "    return data\n",
    "\n",
    "# Preprocess training data with both app and bureau predictions\n",
    "train_enhanced = preprocess_enhanced_data(train_with_bureau, is_training=True)\n",
    "\n",
    "# Preprocess test data with both app and bureau predictions\n",
    "test_enhanced = preprocess_enhanced_data(test_with_bureau, is_training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8a45f3e-dc66-4dd7-9040-57709ce6ec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training enhanced model with cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15494\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 136\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432482\n",
      "[LightGBM] [Info] Start training from score -2.432482\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[427]\tvalid_0's auc: 0.826572\tvalid_0's binary_logloss: 0.220758\n",
      "Fold 1 AUC: 0.8266\n",
      "\n",
      "Fold 2/5\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15579\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 135\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[524]\tvalid_0's auc: 0.830723\tvalid_0's binary_logloss: 0.219147\n",
      "Fold 2 AUC: 0.8307\n",
      "\n",
      "Fold 3/5\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15483\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 136\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid_0's auc: 0.821287\tvalid_0's binary_logloss: 0.223072\n",
      "Fold 3 AUC: 0.8213\n",
      "\n",
      "Fold 4/5\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15491\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 136\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[835]\tvalid_0's auc: 0.825907\tvalid_0's binary_logloss: 0.220142\n",
      "Fold 4 AUC: 0.8259\n",
      "\n",
      "Fold 5/5\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15482\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 136\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[443]\tvalid_0's auc: 0.824057\tvalid_0's binary_logloss: 0.222616\n",
      "Fold 5 AUC: 0.8241\n",
      "\n",
      "Enhanced cross-validation AUC: 0.8257 ± 0.0031\n",
      "Enhanced out-of-fold AUC: 0.8257\n",
      "\n",
      "Top 20 important features:\n",
      "                        feature  importance\n",
      "57                 EXT_SOURCE_2       623.0\n",
      "45       DAYS_LAST_PHONE_CHANGE       511.8\n",
      "58                 EXT_SOURCE_3       503.2\n",
      "56                 EXT_SOURCE_1       499.2\n",
      "18                APP_PRED_MEAN       459.6\n",
      "1                   AMT_ANNUITY       459.6\n",
      "19                 APP_PRED_MIN       452.2\n",
      "2                    AMT_CREDIT       432.0\n",
      "44              DAYS_ID_PUBLISH       426.2\n",
      "32              BUREAU_PRED_MIN       418.8\n",
      "46            DAYS_REGISTRATION       405.6\n",
      "42                   DAYS_BIRTH       387.8\n",
      "43                DAYS_EMPLOYED       385.2\n",
      "23            APP_X_BUREAU_MEAN       375.6\n",
      "17                 APP_PRED_MAX       350.4\n",
      "11      ANNUITY_TO_INCOME_RATIO       348.4\n",
      "124  REGION_POPULATION_RELATIVE       347.0\n",
      "0                     AGE_YEARS       318.2\n",
      "20               APP_PRED_RANGE       317.4\n",
      "31             BUREAU_PRED_MEAN       312.0\n",
      "\n",
      "Ranking of prediction features:\n",
      "Rank 19: APP_PRED_MEAN - Importance: 459.6\n",
      "Rank 20: APP_PRED_MIN - Importance: 452.2\n",
      "Rank 33: BUREAU_PRED_MIN - Importance: 418.8\n",
      "Rank 18: APP_PRED_MAX - Importance: 350.4\n",
      "Rank 21: APP_PRED_RANGE - Importance: 317.4\n",
      "Rank 32: BUREAU_PRED_MEAN - Importance: 312.0\n",
      "Rank 31: BUREAU_PRED_MAX - Importance: 307.0\n",
      "Rank 34: BUREAU_PRED_RANGE - Importance: 278.6\n",
      "Rank 22: APP_PRED_STD - Importance: 265.4\n",
      "Rank 29: BUREAU_PRED_COUNT - Importance: 225.2\n",
      "Rank 35: BUREAU_PRED_STD - Importance: 225.2\n",
      "Rank 16: APP_PRED_COUNT - Importance: 167.6\n",
      "Rank 30: BUREAU_PRED_COUNT_NORM - Importance: 43.8\n",
      "Rank 17: APP_PRED_COUNT_NORM - Importance: 32.0\n"
     ]
    }
   ],
   "source": [
    "def train_enhanced_model_cv(train_data, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Train the enhanced model with cross-validation\n",
    "    \"\"\"\n",
    "    print(\"Training enhanced model with cross-validation...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = train_data.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "    y = train_data['TARGET']\n",
    "    \n",
    "    # Initialize LightGBM classifier\n",
    "    model = lgbm.LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=32,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_weight=2,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Initialize cross-validation\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Lists to store results\n",
    "    cv_scores = []\n",
    "    feature_importance_dfs = []\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    \n",
    "    # Cross-validation loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Train the model with early stopping\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='auc',\n",
    "            callbacks=[lgbm.early_stopping(stopping_rounds=100, verbose=True)]\n",
    "        )\n",
    "        \n",
    "        # Predict on validation set\n",
    "        val_preds = model.predict_proba(X_val)[:, 1]\n",
    "        oof_preds[val_idx] = val_preds\n",
    "        \n",
    "        # Calculate AUC\n",
    "        auc = roc_auc_score(y_val, val_preds)\n",
    "        cv_scores.append(auc)\n",
    "        print(f\"Fold {fold + 1} AUC: {auc:.4f}\")\n",
    "        \n",
    "        # Store feature importance\n",
    "        fold_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': model.feature_importances_\n",
    "        })\n",
    "        fold_importance['fold'] = fold + 1\n",
    "        feature_importance_dfs.append(fold_importance)\n",
    "    \n",
    "    # Calculate overall CV score\n",
    "    cv_score_mean = np.mean(cv_scores)\n",
    "    cv_score_std = np.std(cv_scores)\n",
    "    print(f\"\\nEnhanced cross-validation AUC: {cv_score_mean:.4f} ± {cv_score_std:.4f}\")\n",
    "    \n",
    "    # Calculate overall AUC on out-of-fold predictions\n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"Enhanced out-of-fold AUC: {oof_auc:.4f}\")\n",
    "    \n",
    "    # Combine feature importances from all folds\n",
    "    feature_importance = pd.concat(feature_importance_dfs)\n",
    "    feature_importance_mean = feature_importance.groupby('feature')['importance'].mean().reset_index()\n",
    "    feature_importance_mean = feature_importance_mean.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 important features:\")\n",
    "    print(feature_importance_mean.head(20))\n",
    "    \n",
    "    # Check the rank of our prediction features\n",
    "    pred_features = [col for col in X.columns if 'PRED' in col]\n",
    "    pred_importance = feature_importance_mean[feature_importance_mean['feature'].isin(pred_features)]\n",
    "    print(\"\\nRanking of prediction features:\")\n",
    "    for i, row in pred_importance.iterrows():\n",
    "        rank = feature_importance_mean[feature_importance_mean['feature'] == row['feature']].index[0] + 1\n",
    "        print(f\"Rank {rank}: {row['feature']} - Importance: {row['importance']}\")\n",
    "    \n",
    "    return model, feature_importance_mean, oof_preds, oof_auc\n",
    "\n",
    "# Train enhanced model with cross-validation\n",
    "enhanced_model, enhanced_feature_importance, enhanced_oof_preds, enhanced_oof_auc = train_enhanced_model_cv(train_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e45db68-0d27-45a2-b985-b9e3a97c14a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final enhanced model and generating predictions...\n",
      "[LightGBM] [Info] Number of positive: 24825, number of negative: 282686\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15586\n",
      "[LightGBM] [Info] Number of data points in the train set: 307511, number of used features: 136\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Enhanced submission saved to /Users/braidosan/Downloads/home-credit-default-risk/submission_enhanced_v2.csv\n",
      "Submission predictions range: 0.00020376986972130967 to 0.08797428935237211\n"
     ]
    }
   ],
   "source": [
    "def train_final_enhanced_model_and_predict(train_data, test_data):\n",
    "    \"\"\"\n",
    "    Train the final enhanced model on all training data and make predictions on test data\n",
    "    \"\"\"\n",
    "    print(\"Training final enhanced model and generating predictions...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_train = train_data.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "    y_train = train_data['TARGET']\n",
    "    \n",
    "    # Make sure test data has the same columns as training data\n",
    "    missing_cols = set(X_train.columns) - set(test_data.columns)\n",
    "    for col in missing_cols:\n",
    "        test_data[col] = 0  # Add missing columns with default values\n",
    "        \n",
    "    # Use only the columns that exist in training data\n",
    "    X_test = test_data[X_train.columns]\n",
    "    \n",
    "    # Initialize LightGBM classifier with the parameters that worked well in CV\n",
    "    final_model = lgbm.LGBMClassifier(\n",
    "        n_estimators=600,  # Use a value based on average from CV\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=32,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_weight=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model on all training data\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions on test data\n",
    "    test_preds = final_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission = pd.DataFrame({\n",
    "        'SK_ID_CURR': test_data['SK_ID_CURR'],\n",
    "        'TARGET': test_preds\n",
    "    })\n",
    "    \n",
    "    # Save submission to CSV\n",
    "    submission_path = os.path.join(DATA_DIR, \"submission_enhanced_v2.csv\")\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(f\"Enhanced submission saved to {submission_path}\")\n",
    "    print(f\"Submission predictions range: {submission['TARGET'].min()} to {submission['TARGET'].max()}\")\n",
    "    \n",
    "    return submission, final_model\n",
    "\n",
    "# Train final model and generate predictions\n",
    "enhanced_submission, final_enhanced_model = train_final_enhanced_model_and_predict(train_enhanced, test_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad62a1e5-f573-429a-96a3-0e48bc7e559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of model versions:\n",
      "Version 1 (Application only): CV AUC = 0.8036 ± 0.0044\n",
      "Version 2 (Application + Bureau): CV AUC = 0.8257 ± 0.0031\n",
      "Improvement: 0.0221 AUC\n"
     ]
    }
   ],
   "source": [
    "# Save the enhanced model version\n",
    "version_info = {\n",
    "    'version': 'two_stage_v2',\n",
    "    'cv_auc': 0.8257,\n",
    "    'cv_std': 0.0031,\n",
    "    'description': 'Two-stage model with both application and bureau level predictions',\n",
    "    'feature_importance': enhanced_feature_importance\n",
    "}\n",
    "\n",
    "# Create a results directory if it doesn't exist\n",
    "results_dir = os.path.join(DATA_DIR, 'model_versions')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save models and results\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(results_dir, 'two_stage_v2_app_level_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(app_level_model, f)\n",
    "\n",
    "with open(os.path.join(results_dir, 'two_stage_v2_bureau_level_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(bureau_level_model, f)\n",
    "    \n",
    "with open(os.path.join(results_dir, 'two_stage_v2_final_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(final_enhanced_model, f)\n",
    "    \n",
    "with open(os.path.join(results_dir, 'two_stage_v2_info.pkl'), 'wb') as f:\n",
    "    pickle.dump(version_info, f)\n",
    "\n",
    "# Save a copy of the submission with version number\n",
    "enhanced_submission.to_csv(os.path.join(results_dir, 'submission_two_stage_v2.csv'), index=False)\n",
    "\n",
    "print(\"\\nComparison of model versions:\")\n",
    "print(\"Version 1 (Application only): CV AUC = 0.8036 ± 0.0044\")\n",
    "print(\"Version 2 (Application + Bureau): CV AUC = 0.8257 ± 0.0031\")\n",
    "print(f\"Improvement: {0.8257 - 0.8036:.4f} AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b9f130b-cd3b-444b-a2ce-f7d8caa4e64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating basic network features...\n",
      "Available columns: ['SK_ID_PREV', 'SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT', 'AMT_DOWN_PAYMENT', 'AMT_GOODS_PRICE', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'FLAG_LAST_APPL_PER_CONTRACT', 'NFLAG_LAST_APPL_IN_DAY', 'RATE_DOWN_PAYMENT', 'RATE_INTEREST_PRIMARY', 'RATE_INTEREST_PRIVILEGED', 'NAME_CASH_LOAN_PURPOSE', 'NAME_CONTRACT_STATUS', 'DAYS_DECISION', 'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON', 'NAME_TYPE_SUITE', 'NAME_CLIENT_TYPE', 'NAME_GOODS_CATEGORY', 'NAME_PORTFOLIO', 'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE', 'SELLERPLACE_AREA', 'NAME_SELLER_INDUSTRY', 'CNT_PAYMENT', 'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION', 'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE', 'DAYS_TERMINATION', 'NFLAG_INSURED_ON_APPROVAL']\n",
      "Grouping applications by customer...\n",
      "Calculating aggregated features...\n",
      "Network features created: (338857, 17)\n",
      "Columns: ['SK_ID_CURR', 'NET_SK_ID_PREV_COUNT', 'NET_DAYS_DECISION_MEAN', 'NET_DAYS_DECISION_MIN', 'NET_DAYS_DECISION_MAX', 'NET_NAME_CONTRACT_TYPE_NUNIQUE', 'NET_NAME_CONTRACT_STATUS_<LAMBDA>', 'NET_AMT_CREDIT_MEAN', 'NET_AMT_CREDIT_MIN', 'NET_AMT_CREDIT_MAX', 'NET_AMT_ANNUITY_MEAN', 'NET_AMT_ANNUITY_MIN', 'NET_AMT_ANNUITY_MAX', 'NET_COUNT_Approved', 'NET_COUNT_Canceled', 'NET_COUNT_Refused', 'NET_COUNT_Unused offer']\n"
     ]
    }
   ],
   "source": [
    "def create_basic_network_features():\n",
    "    \"\"\"\n",
    "    Create very basic network features with only columns we know exist\n",
    "    \"\"\"\n",
    "    print(\"Creating basic network features...\")\n",
    "    \n",
    "    # Check which columns actually exist\n",
    "    print(f\"Available columns: {prev_df.columns.tolist()}\")\n",
    "    \n",
    "    # Group applications by customer\n",
    "    print(\"Grouping applications by customer...\")\n",
    "    app_groups = prev_df.groupby('SK_ID_CURR')\n",
    "    \n",
    "    # Basic features through direct aggregation\n",
    "    print(\"Calculating aggregated features...\")\n",
    "    agg_dict = {\n",
    "        'SK_ID_PREV': 'count',  # Number of previous applications\n",
    "        'DAYS_DECISION': ['mean', 'min', 'max'],  # Time-related features\n",
    "        'NAME_CONTRACT_TYPE': 'nunique',  # Contract type diversity\n",
    "        'NAME_CONTRACT_STATUS': lambda x: x.value_counts().get('Approved', 0) / len(x) if len(x) > 0 else 0  # Approval ratio\n",
    "    }\n",
    "    \n",
    "    # Add credit-related columns if they exist\n",
    "    if 'AMT_CREDIT' in prev_df.columns:\n",
    "        agg_dict['AMT_CREDIT'] = ['mean', 'min', 'max']\n",
    "    \n",
    "    if 'AMT_ANNUITY' in prev_df.columns:\n",
    "        agg_dict['AMT_ANNUITY'] = ['mean', 'min', 'max']\n",
    "    \n",
    "    network_agg = app_groups.agg(agg_dict)\n",
    "    \n",
    "    # Flatten column names\n",
    "    network_agg.columns = [f'NET_{col[0]}_{col[1].upper()}' if isinstance(col, tuple) else f'NET_{col}' \n",
    "                          for col in network_agg.columns]\n",
    "    \n",
    "    # Add more features based on counts\n",
    "    status_counts = prev_df.pivot_table(\n",
    "        index='SK_ID_CURR', \n",
    "        columns='NAME_CONTRACT_STATUS', \n",
    "        values='SK_ID_PREV',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    # Rename columns\n",
    "    status_counts = status_counts.add_prefix('NET_COUNT_')\n",
    "    \n",
    "    # Merge with network features\n",
    "    network_agg = network_agg.reset_index()\n",
    "    if not status_counts.empty:\n",
    "        status_counts = status_counts.reset_index()\n",
    "        network_agg = network_agg.merge(status_counts, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    # Fill NAs\n",
    "    network_agg = network_agg.fillna(0)\n",
    "    \n",
    "    print(f\"Network features created: {network_agg.shape}\")\n",
    "    print(f\"Columns: {network_agg.columns.tolist()}\")\n",
    "    \n",
    "    return network_agg\n",
    "\n",
    "# Create basic network features\n",
    "network_features_df = create_basic_network_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a128107-5c2b-4e4a-9ad9-d9960da6265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_network_features_to_data(train_data, test_data, network_features_df):\n",
    "    \"\"\"\n",
    "    Add network features to training and test data\n",
    "    \"\"\"\n",
    "    print(\"Adding network features to data...\")\n",
    "    \n",
    "    # Add to training data\n",
    "    train_with_network = train_data.merge(network_features_df, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    # Prepare test network features\n",
    "    test_ids = test_data['SK_ID_CURR'].unique()\n",
    "    test_network_features = network_features_df[network_features_df['SK_ID_CURR'].isin(test_ids)]\n",
    "    \n",
    "    # Add to test data\n",
    "    test_with_network = test_data.merge(test_network_features, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    # Fill missing values\n",
    "    network_cols = [col for col in network_features_df.columns if col != 'SK_ID_CURR']\n",
    "    for col in network_cols:\n",
    "        train_with_network[col] = train_with_network[col].fillna(0)\n",
    "        test_with_network[col] = test_with_network[col].fillna(0)\n",
    "    \n",
    "    print(f\"Training data with network features shape: {train_with_network.shape}\")\n",
    "    print(f\"Test data with network features shape: {test_with_network.shape}\")\n",
    "    \n",
    "    return train_with_network, test_with_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b7f83c7-7f87-4349-9c66-a4cd626bc2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding network features to data...\n",
      "Training data with network features shape: (307511, 158)\n",
      "Test data with network features shape: (48744, 157)\n"
     ]
    }
   ],
   "source": [
    "# Add network features to our data\n",
    "train_with_network, test_with_network = add_network_features_to_data(train_enhanced, test_enhanced, network_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "060134b3-53e9-41c7-b244-beef30cf3672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data with network features...\n",
      "Preprocessing complete. Data shape: (307511, 161)\n",
      "Preprocessing test data with network features...\n",
      "Preprocessing complete. Data shape: (48744, 160)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_network_data(df, is_training=True):\n",
    "    \"\"\"\n",
    "    Preprocess the data with network features\n",
    "    \"\"\"\n",
    "    print(f\"Preprocessing {'training' if is_training else 'test'} data with network features...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying original data\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Handle missing values in numerical columns\n",
    "    num_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in num_cols:\n",
    "        # Skip TARGET and identifier columns\n",
    "        if col in ['TARGET', 'SK_ID_CURR']:\n",
    "            continue\n",
    "            \n",
    "        # Replace infinity values with NaN\n",
    "        data[col] = data[col].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Fill NaN with median\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "    \n",
    "    # Handle categorical columns\n",
    "    cat_cols = data.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        # Fill missing with 'Unknown'\n",
    "        data[col] = data[col].fillna('Unknown')\n",
    "        \n",
    "        # Label encode categorical variables\n",
    "        if col not in ['SK_ID_CURR']:\n",
    "            le = LabelEncoder()\n",
    "            data[col] = le.fit_transform(data[col])\n",
    "    \n",
    "    # Create ratio features from network features\n",
    "    # Approval to refusal ratio\n",
    "    if 'NET_COUNT_Approved' in data.columns and 'NET_COUNT_Refused' in data.columns:\n",
    "        data['NET_RATIO_APPROVED_TO_REFUSED'] = data['NET_COUNT_Approved'] / (data['NET_COUNT_Refused'] + 1)\n",
    "    \n",
    "    # Credit amount growth\n",
    "    if 'NET_AMT_CREDIT_MAX' in data.columns and 'NET_AMT_CREDIT_MIN' in data.columns:\n",
    "        data['NET_CREDIT_GROWTH_RATIO'] = data['NET_AMT_CREDIT_MAX'] / (data['NET_AMT_CREDIT_MIN'] + 1)\n",
    "    \n",
    "    # Time span of applications\n",
    "    if 'NET_DAYS_DECISION_MAX' in data.columns and 'NET_DAYS_DECISION_MIN' in data.columns:\n",
    "        data['NET_DAYS_DECISION_SPAN'] = data['NET_DAYS_DECISION_MAX'] - data['NET_DAYS_DECISION_MIN']\n",
    "    \n",
    "    # Fill any NaNs created by division\n",
    "    for col in data.columns:\n",
    "        if col not in ['SK_ID_CURR', 'TARGET']:\n",
    "            data[col] = data[col].replace([np.inf, -np.inf], np.nan)\n",
    "            data[col] = data[col].fillna(0)\n",
    "    \n",
    "    print(f\"Preprocessing complete. Data shape: {data.shape}\")\n",
    "    return data\n",
    "\n",
    "# Preprocess data with network features\n",
    "train_network_processed = preprocess_network_data(train_with_network, is_training=True)\n",
    "test_network_processed = preprocess_network_data(test_with_network, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f8e1e4a-871b-407c-95f5-5fe86503c009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with network features using cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18678\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 155\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432482\n",
      "[LightGBM] [Info] Start training from score -2.432482\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[722]\tvalid_0's auc: 0.833068\tvalid_0's binary_logloss: 0.217306\n",
      "Fold 1 AUC: 0.8331\n",
      "\n",
      "Fold 2/5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18751\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 154\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's auc: 0.837741\tvalid_0's binary_logloss: 0.215481\n",
      "Fold 2 AUC: 0.8377\n",
      "\n",
      "Fold 3/5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18657\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 155\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[424]\tvalid_0's auc: 0.826026\tvalid_0's binary_logloss: 0.220373\n",
      "Fold 3 AUC: 0.8260\n",
      "\n",
      "Fold 4/5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.383287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18741\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 155\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[602]\tvalid_0's auc: 0.832684\tvalid_0's binary_logloss: 0.216942\n",
      "Fold 4 AUC: 0.8327\n",
      "\n",
      "Fold 5/5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18663\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 155\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's auc: 0.828939\tvalid_0's binary_logloss: 0.219814\n",
      "Fold 5 AUC: 0.8289\n",
      "\n",
      "Network model cross-validation AUC: 0.8317 ± 0.0040\n",
      "Network model out-of-fold AUC: 0.8317\n",
      "\n",
      "Top 20 important features:\n",
      "                        feature  importance\n",
      "57                 EXT_SOURCE_2       543.4\n",
      "18                APP_PRED_MEAN       521.6\n",
      "56                 EXT_SOURCE_1       440.2\n",
      "58                 EXT_SOURCE_3       422.8\n",
      "1                   AMT_ANNUITY       406.4\n",
      "19                 APP_PRED_MIN       403.0\n",
      "125      NET_DAYS_DECISION_MEAN       400.4\n",
      "32              BUREAU_PRED_MIN       364.8\n",
      "2                    AMT_CREDIT       355.2\n",
      "44              DAYS_ID_PUBLISH       346.2\n",
      "46            DAYS_REGISTRATION       344.4\n",
      "23            APP_X_BUREAU_MEAN       342.4\n",
      "42                   DAYS_BIRTH       325.6\n",
      "17                 APP_PRED_MAX       320.2\n",
      "126       NET_DAYS_DECISION_MIN       310.8\n",
      "45       DAYS_LAST_PHONE_CHANGE       300.6\n",
      "43                DAYS_EMPLOYED       294.0\n",
      "124       NET_DAYS_DECISION_MAX       292.6\n",
      "143  REGION_POPULATION_RELATIVE       284.8\n",
      "30              BUREAU_PRED_MAX       268.0\n",
      "\n",
      "Top network features:\n",
      "                           feature  importance\n",
      "125         NET_DAYS_DECISION_MEAN       400.4\n",
      "126          NET_DAYS_DECISION_MIN       310.8\n",
      "124          NET_DAYS_DECISION_MAX       292.6\n",
      "114           NET_AMT_ANNUITY_MEAN       262.6\n",
      "115            NET_AMT_ANNUITY_MIN       247.0\n",
      "130  NET_RATIO_APPROVED_TO_REFUSED       239.4\n",
      "117            NET_AMT_CREDIT_MEAN       236.8\n",
      "116             NET_AMT_CREDIT_MAX       231.8\n",
      "123        NET_CREDIT_GROWTH_RATIO       207.4\n",
      "113            NET_AMT_ANNUITY_MAX       205.6\n"
     ]
    }
   ],
   "source": [
    "def train_network_model_cv(train_data, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Train model with network features using cross-validation\n",
    "    \"\"\"\n",
    "    print(\"Training model with network features using cross-validation...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = train_data.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "    y = train_data['TARGET']\n",
    "    \n",
    "    # Initialize LightGBM classifier\n",
    "    model = lgbm.LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=32,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_weight=2,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Initialize cross-validation\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Lists to store results\n",
    "    cv_scores = []\n",
    "    feature_importance_dfs = []\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    \n",
    "    # Cross-validation loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Train the model with early stopping\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='auc',\n",
    "            callbacks=[lgbm.early_stopping(stopping_rounds=100, verbose=True)]\n",
    "        )\n",
    "        \n",
    "        # Predict on validation set\n",
    "        val_preds = model.predict_proba(X_val)[:, 1]\n",
    "        oof_preds[val_idx] = val_preds\n",
    "        \n",
    "        # Calculate AUC\n",
    "        auc = roc_auc_score(y_val, val_preds)\n",
    "        cv_scores.append(auc)\n",
    "        print(f\"Fold {fold + 1} AUC: {auc:.4f}\")\n",
    "        \n",
    "        # Store feature importance\n",
    "        fold_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': model.feature_importances_\n",
    "        })\n",
    "        fold_importance['fold'] = fold + 1\n",
    "        feature_importance_dfs.append(fold_importance)\n",
    "    \n",
    "    # Calculate overall CV score\n",
    "    cv_score_mean = np.mean(cv_scores)\n",
    "    cv_score_std = np.std(cv_scores)\n",
    "    print(f\"\\nNetwork model cross-validation AUC: {cv_score_mean:.4f} ± {cv_score_std:.4f}\")\n",
    "    \n",
    "    # Calculate overall AUC on out-of-fold predictions\n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"Network model out-of-fold AUC: {oof_auc:.4f}\")\n",
    "    \n",
    "    # Combine feature importances from all folds\n",
    "    feature_importance = pd.concat(feature_importance_dfs)\n",
    "    feature_importance_mean = feature_importance.groupby('feature')['importance'].mean().reset_index()\n",
    "    feature_importance_mean = feature_importance_mean.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 important features:\")\n",
    "    print(feature_importance_mean.head(20))\n",
    "    \n",
    "    # Check the rank of our network features\n",
    "    network_features = [col for col in X.columns if col.startswith('NET_')]\n",
    "    network_importance = feature_importance_mean[feature_importance_mean['feature'].isin(network_features)]\n",
    "    \n",
    "    if not network_importance.empty:\n",
    "        print(\"\\nTop network features:\")\n",
    "        print(network_importance.head(10))\n",
    "    \n",
    "    return model, feature_importance_mean, oof_preds, oof_auc\n",
    "\n",
    "# Train model with network features\n",
    "network_model, network_feature_importance, network_oof_preds, network_oof_auc = train_network_model_cv(train_network_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ef36854-7447-40e2-ad4a-3adf7982baf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final network model and generating predictions...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 24825, number of negative: 282686\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18829\n",
      "[LightGBM] [Info] Number of data points in the train set: 307511, number of used features: 155\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Network model submission saved to /Users/braidosan/Downloads/home-credit-default-risk/submission_network_v3.csv\n",
      "Submission predictions range: 0.00017559232806889515 to 0.08110143062292013\n"
     ]
    }
   ],
   "source": [
    "def train_final_network_model_and_predict(train_data, test_data):\n",
    "    \"\"\"\n",
    "    Train the final model with network features and make predictions\n",
    "    \"\"\"\n",
    "    print(\"Training final network model and generating predictions...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_train = train_data.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "    y_train = train_data['TARGET']\n",
    "    \n",
    "    # Make sure test data has the same columns as training data\n",
    "    missing_cols = set(X_train.columns) - set(test_data.columns)\n",
    "    for col in missing_cols:\n",
    "        test_data[col] = 0  # Add missing columns with default values\n",
    "        \n",
    "    # Use only the columns that exist in training data\n",
    "    X_test = test_data[X_train.columns]\n",
    "    \n",
    "    # Initialize LightGBM classifier with the parameters that worked well in CV\n",
    "    final_model = lgbm.LGBMClassifier(\n",
    "        n_estimators=550,  # Based on average from CV (464-722)\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=32,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_weight=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model on all training data\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions on test data\n",
    "    test_preds = final_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission = pd.DataFrame({\n",
    "        'SK_ID_CURR': test_data['SK_ID_CURR'],\n",
    "        'TARGET': test_preds\n",
    "    })\n",
    "    \n",
    "    # Save submission to CSV\n",
    "    submission_path = os.path.join(DATA_DIR, \"submission_network_v3.csv\")\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(f\"Network model submission saved to {submission_path}\")\n",
    "    print(f\"Submission predictions range: {submission['TARGET'].min()} to {submission['TARGET'].max()}\")\n",
    "    \n",
    "    return submission, final_model\n",
    "\n",
    "# Train final network model and make predictions\n",
    "network_submission, final_network_model = train_final_network_model_and_predict(train_network_processed, test_network_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2bd575a6-1872-4db6-bb03-d4e1ce872988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Version Comparison:\n",
      "Version 1 (Application only): CV AUC = 0.8036 ± 0.0044\n",
      "Version 2 (Application + Bureau): CV AUC = 0.8257 ± 0.0031\n",
      "Version 3 (Application + Bureau + Network): CV AUC = 0.8317 ± 0.0040\n",
      "Total Improvement: 0.0281 AUC\n"
     ]
    }
   ],
   "source": [
    "# Save the enhanced model with network features\n",
    "version_info = {\n",
    "    'version': 'two_stage_v3',\n",
    "    'cv_auc': 0.8317,\n",
    "    'cv_std': 0.0040,\n",
    "    'description': 'Two-stage model with application, bureau and network features',\n",
    "    'feature_importance': network_feature_importance\n",
    "}\n",
    "\n",
    "# Create a results directory if it doesn't exist\n",
    "results_dir = os.path.join(DATA_DIR, 'model_versions')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save models and results\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(results_dir, 'two_stage_v3_app_level_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(app_level_model, f)\n",
    "\n",
    "with open(os.path.join(results_dir, 'two_stage_v3_bureau_level_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(bureau_level_model, f)\n",
    "    \n",
    "with open(os.path.join(results_dir, 'two_stage_v3_final_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(final_network_model, f)\n",
    "    \n",
    "with open(os.path.join(results_dir, 'two_stage_v3_info.pkl'), 'wb') as f:\n",
    "    pickle.dump(version_info, f)\n",
    "\n",
    "# Save a copy of the submission with version number\n",
    "network_submission.to_csv(os.path.join(results_dir, 'submission_two_stage_v3.csv'), index=False)\n",
    "\n",
    "print(\"\\nModel Version Comparison:\")\n",
    "print(\"Version 1 (Application only): CV AUC = 0.8036 ± 0.0044\")\n",
    "print(\"Version 2 (Application + Bureau): CV AUC = 0.8257 ± 0.0031\")\n",
    "print(\"Version 3 (Application + Bureau + Network): CV AUC = 0.8317 ± 0.0040\")\n",
    "print(f\"Total Improvement: {0.8317 - 0.8036:.4f} AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68bfe384-d283-44f6-93de-fa523fc95ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for potential target leakage...\n",
      "\n",
      "Correlation between TARGET and prediction features:\n",
      "TARGET                    1.000000\n",
      "BUREAU_PRED_STD           0.146236\n",
      "BUREAU_PRED_RANGE         0.140835\n",
      "APP_PRED_STD              0.135133\n",
      "APP_PRED_RANGE            0.134520\n",
      "BUREAU_PRED_MAX           0.102559\n",
      "APP_PRED_MAX              0.100659\n",
      "BUREAU_PRED_MEAN          0.068172\n",
      "APP_PRED_MEAN             0.060168\n",
      "BUREAU_PRED_MIN           0.050847\n",
      "APP_PRED_MIN              0.033738\n",
      "APP_PRED_COUNT            0.023513\n",
      "APP_PRED_COUNT_NORM       0.019978\n",
      "BUREAU_PRED_COUNT        -0.010020\n",
      "BUREAU_PRED_COUNT_NORM   -0.024155\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Checking application level model features...\n",
      "Any 'TARGET' in application level model features: False\n",
      "\n",
      "Checking bureau level model features...\n",
      "Any 'TARGET' in bureau level model features: False\n",
      "\n",
      "Checking network features for TARGET usage...\n",
      "Any 'TARGET' in network feature names: False\n"
     ]
    }
   ],
   "source": [
    "def check_target_leakage():\n",
    "    \"\"\"\n",
    "    Check for potential target leakage in our features\n",
    "    \"\"\"\n",
    "    print(\"Checking for potential target leakage...\")\n",
    "    \n",
    "    # 1. Check correlation between TARGET and our prediction features\n",
    "    train_corr = train_network_processed[['TARGET'] + \n",
    "                 [col for col in train_network_processed.columns if 'PRED' in col]]\n",
    "    \n",
    "    print(\"\\nCorrelation between TARGET and prediction features:\")\n",
    "    target_corrs = train_corr.corr()['TARGET'].sort_values(ascending=False)\n",
    "    print(target_corrs)\n",
    "    \n",
    "    # 2. Check that our application and bureau level models only used correct data\n",
    "    print(\"\\nChecking application level model features...\")\n",
    "    app_features = app_level_model.feature_name_\n",
    "    print(f\"Any 'TARGET' in application level model features: {'TARGET' in app_features}\")\n",
    "    \n",
    "    print(\"\\nChecking bureau level model features...\")\n",
    "    bureau_features = bureau_level_model.feature_name_\n",
    "    print(f\"Any 'TARGET' in bureau level model features: {'TARGET' in bureau_features}\")\n",
    "    \n",
    "    # 3. Check that network features don't directly use TARGET\n",
    "    print(\"\\nChecking network features for TARGET usage...\")\n",
    "    network_cols = [col for col in network_features_df.columns if col != 'SK_ID_CURR']\n",
    "    print(f\"Any 'TARGET' in network feature names: {any('TARGET' in col for col in network_cols)}\")\n",
    "    \n",
    "    return target_corrs\n",
    "\n",
    "# Check for target leakage\n",
    "target_correlations = check_target_leakage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1a53f76-1dae-40eb-aa8d-4ac6bb91e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking train-test separation...\n",
      "Any overlap between train and test customer IDs: False\n",
      "\n",
      "Checking cross-validation implementation...\n",
      "Our CV used StratifiedKFold with n_splits=5, which ensures:\n",
      "- No sample is used for both training and validation within a fold\n",
      "- Class distribution is maintained across folds\n",
      "- Each sample is used exactly once for validation\n"
     ]
    }
   ],
   "source": [
    "def check_train_test_separation():\n",
    "    \"\"\"\n",
    "    Check that our train and test sets are properly separated\n",
    "    \"\"\"\n",
    "    print(\"\\nChecking train-test separation...\")\n",
    "    \n",
    "    # 1. Check that there's no overlap in SK_ID_CURR between train and test\n",
    "    train_ids = set(train_df['SK_ID_CURR'])\n",
    "    test_ids = set(test_df['SK_ID_CURR'])\n",
    "    overlap = train_ids.intersection(test_ids)\n",
    "    \n",
    "    print(f\"Any overlap between train and test customer IDs: {len(overlap) > 0}\")\n",
    "    if len(overlap) > 0:\n",
    "        print(f\"Number of overlapping IDs: {len(overlap)}\")\n",
    "    \n",
    "    # 2. Check that app-level predictions for test were generated without using test TARGET\n",
    "    # We need to check how test_app_preds was generated\n",
    "    # In our implementation, app_level_model was only trained on train data with TARGET\n",
    "    # And then used to predict on test data without TARGET\n",
    "    \n",
    "    # 3. Verify our CV implementation\n",
    "    print(\"\\nChecking cross-validation implementation...\")\n",
    "    print(\"Our CV used StratifiedKFold with n_splits=5, which ensures:\")\n",
    "    print(\"- No sample is used for both training and validation within a fold\")\n",
    "    print(\"- Class distribution is maintained across folds\")\n",
    "    print(\"- Each sample is used exactly once for validation\")\n",
    "    \n",
    "    return len(overlap) == 0\n",
    "\n",
    "# Check train-test separation\n",
    "train_test_properly_separated = check_train_test_separation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "773fc653-3c03-4e23-910e-245f014cbd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking feature distributions...\n",
      "\n",
      "Application prediction feature statistics:\n",
      "\n",
      "Train statistics:\n",
      "                         mean       std       min        max\n",
      "APP_PRED_MEAN        0.108389  0.097889  0.006035   0.545570\n",
      "APP_PRED_MAX         0.135850  0.099052  0.006035   0.849800\n",
      "APP_PRED_MIN         0.086071  0.102832  0.004892   0.545570\n",
      "APP_PRED_STD         0.020779  0.019247  0.000000   0.308032\n",
      "APP_PRED_COUNT       4.597237  4.180015  0.000000  73.000000\n",
      "APP_PRED_RANGE       0.049779  0.048329  0.000000   0.784765\n",
      "APP_PRED_COUNT_NORM  1.484134  0.698077  0.000000   4.304065\n",
      "\n",
      "Test statistics:\n",
      "                     mean  std  min  max\n",
      "APP_PRED_MEAN         0.0  0.0  0.0  0.0\n",
      "APP_PRED_MAX          0.0  0.0  0.0  0.0\n",
      "APP_PRED_MIN          0.0  0.0  0.0  0.0\n",
      "APP_PRED_STD          0.0  0.0  0.0  0.0\n",
      "APP_PRED_COUNT        0.0  0.0  0.0  0.0\n",
      "APP_PRED_RANGE        0.0  0.0  0.0  0.0\n",
      "APP_PRED_COUNT_NORM   0.0  0.0  0.0  0.0\n",
      "\n",
      "Bureau prediction feature statistics:\n",
      "\n",
      "Train statistics:\n",
      "                            mean       std       min         max\n",
      "BUREAU_PRED_MEAN        0.139292  0.149341  0.007213    0.837661\n",
      "BUREAU_PRED_MAX         0.165224  0.144548  0.007213    0.926440\n",
      "BUREAU_PRED_MIN         0.122463  0.155746  0.002759    0.781985\n",
      "BUREAU_PRED_STD         0.017101  0.019454  0.000000    0.515537\n",
      "BUREAU_PRED_COUNT       4.765114  4.496199  0.000000  116.000000\n",
      "BUREAU_PRED_RANGE       0.042761  0.049033  0.000000    0.899463\n",
      "BUREAU_PRED_COUNT_NORM  1.443797  0.827476  0.000000    4.762174\n",
      "\n",
      "Test statistics:\n",
      "                            mean       std       min        max\n",
      "BUREAU_PRED_MEAN        0.133924  0.144259  0.003982   0.500000\n",
      "BUREAU_PRED_MAX         0.163762  0.139153  0.003982   0.701962\n",
      "BUREAU_PRED_MIN         0.115058  0.151327  0.002849   0.500000\n",
      "BUREAU_PRED_STD         0.018900  0.019534  0.000000   0.312629\n",
      "BUREAU_PRED_COUNT       5.151465  4.843972  0.000000  78.000000\n",
      "BUREAU_PRED_RANGE       0.048704  0.051785  0.000000   0.653064\n",
      "BUREAU_PRED_COUNT_NORM  1.503181  0.837390  0.000000   4.369448\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_feature_distributions():\n",
    "    \"\"\"\n",
    "    Check the distributions of key prediction features in train and test\n",
    "    Unusual patterns might indicate leakage\n",
    "    \"\"\"\n",
    "    print(\"\\nChecking feature distributions...\")\n",
    "    \n",
    "    # 1. Compare app-level prediction distributions\n",
    "    app_pred_cols = [col for col in train_network_processed.columns if 'APP_PRED' in col]\n",
    "    \n",
    "    print(\"\\nApplication prediction feature statistics:\")\n",
    "    print(\"\\nTrain statistics:\")\n",
    "    print(train_network_processed[app_pred_cols].describe().T[['mean', 'std', 'min', 'max']])\n",
    "    \n",
    "    print(\"\\nTest statistics:\")\n",
    "    print(test_network_processed[app_pred_cols].describe().T[['mean', 'std', 'min', 'max']])\n",
    "    \n",
    "    # 2. Compare bureau-level prediction distributions\n",
    "    bureau_pred_cols = [col for col in train_network_processed.columns if 'BUREAU_PRED' in col]\n",
    "    \n",
    "    print(\"\\nBureau prediction feature statistics:\")\n",
    "    print(\"\\nTrain statistics:\")\n",
    "    print(train_network_processed[bureau_pred_cols].describe().T[['mean', 'std', 'min', 'max']])\n",
    "    \n",
    "    print(\"\\nTest statistics:\")\n",
    "    print(test_network_processed[bureau_pred_cols].describe().T[['mean', 'std', 'min', 'max']])\n",
    "    \n",
    "    # 3. Plot distributions of key prediction features to check for anomalies\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # App prediction means\n",
    "    axes[0, 0].hist(train_network_processed['APP_PRED_MEAN'], bins=50, alpha=0.5, label='Train')\n",
    "    axes[0, 0].hist(test_network_processed['APP_PRED_MEAN'], bins=50, alpha=0.5, label='Test')\n",
    "    axes[0, 0].set_title('APP_PRED_MEAN Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Bureau prediction means\n",
    "    axes[0, 1].hist(train_network_processed['BUREAU_PRED_MEAN'], bins=50, alpha=0.5, label='Train')\n",
    "    axes[0, 1].hist(test_network_processed['BUREAU_PRED_MEAN'], bins=50, alpha=0.5, label='Test')\n",
    "    axes[0, 1].set_title('BUREAU_PRED_MEAN Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Key network features\n",
    "    if 'NET_DAYS_DECISION_MEAN' in train_network_processed.columns:\n",
    "        axes[1, 0].hist(train_network_processed['NET_DAYS_DECISION_MEAN'], bins=50, alpha=0.5, label='Train')\n",
    "        axes[1, 0].hist(test_network_processed['NET_DAYS_DECISION_MEAN'], bins=50, alpha=0.5, label='Test')\n",
    "        axes[1, 0].set_title('NET_DAYS_DECISION_MEAN Distribution')\n",
    "        axes[1, 0].legend()\n",
    "    \n",
    "    if 'NET_APPROVED_RATIO' in train_network_processed.columns:\n",
    "        axes[1, 1].hist(train_network_processed['NET_APPROVED_RATIO'], bins=50, alpha=0.5, label='Train')\n",
    "        axes[1, 1].hist(test_network_processed['NET_APPROVED_RATIO'], bins=50, alpha=0.5, label='Test')\n",
    "        axes[1, 1].set_title('NET_APPROVED_RATIO Distribution')\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Check feature distributions\n",
    "check_feature_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e2c09963-354d-473f-a811-69257c151bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking model complexity and convergence...\n",
      "Number of features in final model: 159\n",
      "\n",
      "Early stopping iterations across folds:\n",
      "Fold 1: 722\n",
      "Fold 2: 464\n",
      "Fold 3: 424\n",
      "Fold 4: 602\n",
      "Fold 5: 464\n",
      "Average: 535.2\n",
      "\n",
      "Top 10 features by importance:\n",
      "                    feature  importance\n",
      "57             EXT_SOURCE_2       543.4\n",
      "18            APP_PRED_MEAN       521.6\n",
      "56             EXT_SOURCE_1       440.2\n",
      "58             EXT_SOURCE_3       422.8\n",
      "1               AMT_ANNUITY       406.4\n",
      "19             APP_PRED_MIN       403.0\n",
      "125  NET_DAYS_DECISION_MEAN       400.4\n",
      "32          BUREAU_PRED_MIN       364.8\n",
      "2                AMT_CREDIT       355.2\n",
      "44          DAYS_ID_PUBLISH       346.2\n",
      "\n",
      "Prediction range in submission:\n",
      "Min: 0.00017559232806889515\n",
      "Max: 0.08110143062292013\n",
      "Mean: 0.0022226260835560706\n",
      "\n",
      "CV scores progression:\n",
      "Original model: 0.7839 ± 0.0036\n",
      "Version 1 (Application): 0.8036 ± 0.0044\n",
      "Version 2 (Application + Bureau): 0.8257 ± 0.0031\n",
      "Version 3 (Application + Bureau + Network): 0.8317 ± 0.0040\n",
      "\n",
      "Step improvements:\n",
      "Step 1: +0.0197\n",
      "Step 2: +0.0221\n",
      "Step 3: +0.0060\n"
     ]
    }
   ],
   "source": [
    "def check_model_complexity():\n",
    "    \"\"\"\n",
    "    Check model complexity and convergence patterns\n",
    "    \"\"\"\n",
    "    print(\"\\nChecking model complexity and convergence...\")\n",
    "    \n",
    "    # 1. Check number of features used in final model\n",
    "    print(f\"Number of features in final model: {len(network_model.feature_name_)}\")\n",
    "    \n",
    "    # 2. Check early stopping pattern in CV folds\n",
    "    print(\"\\nEarly stopping iterations across folds:\")\n",
    "    print(\"Fold 1: 722\")\n",
    "    print(\"Fold 2: 464\")\n",
    "    print(\"Fold 3: 424\")\n",
    "    print(\"Fold 4: 602\")\n",
    "    print(\"Fold 5: 464\")\n",
    "    print(\"Average: 535.2\")\n",
    "    \n",
    "    # 3. Check if feature importances make intuitive sense\n",
    "    print(\"\\nTop 10 features by importance:\")\n",
    "    print(network_feature_importance.head(10))\n",
    "    \n",
    "    # 4. Check prediction range\n",
    "    print(\"\\nPrediction range in submission:\")\n",
    "    print(f\"Min: {network_submission['TARGET'].min()}\")\n",
    "    print(f\"Max: {network_submission['TARGET'].max()}\")\n",
    "    print(f\"Mean: {network_submission['TARGET'].mean()}\")\n",
    "    \n",
    "    # 5. Compare with original model prediction range as a sanity check\n",
    "    # This would require loading the original submission file\n",
    "    \n",
    "    # 6. Compare CV scores across models\n",
    "    print(\"\\nCV scores progression:\")\n",
    "    print(\"Original model: 0.7839 ± 0.0036\")\n",
    "    print(\"Version 1 (Application): 0.8036 ± 0.0044\")\n",
    "    print(\"Version 2 (Application + Bureau): 0.8257 ± 0.0031\")\n",
    "    print(\"Version 3 (Application + Bureau + Network): 0.8317 ± 0.0040\")\n",
    "    \n",
    "    # Reasonable step improvements\n",
    "    print(\"\\nStep improvements:\")\n",
    "    print(f\"Step 1: +{0.8036 - 0.7839:.4f}\")\n",
    "    print(f\"Step 2: +{0.8257 - 0.8036:.4f}\")\n",
    "    print(f\"Step 3: +{0.8317 - 0.8257:.4f}\")\n",
    "\n",
    "# Check model complexity\n",
    "check_model_complexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4efbf404-f5fd-42bf-b32a-98e1fafead20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing application-level predictions for test set...\n",
      "Test previous applications: (256513, 37)\n",
      "Preprocessing application-level features...\n",
      "Preprocessing complete. Data shape: (256513, 42)\n",
      "Fixed test application predictions shape: (48744, 8)\n",
      "\n",
      "Fixed test application prediction statistics:\n",
      "                              mean            std            min  \\\n",
      "SK_ID_CURR           277796.676350  103169.547296  100001.000000   \n",
      "APP_PRED_MEAN             0.091107       0.063338       0.007564   \n",
      "APP_PRED_MAX              0.120213       0.069155       0.007564   \n",
      "APP_PRED_MIN              0.067924       0.066643       0.006013   \n",
      "APP_PRED_STD              0.021113       0.017445       0.000000   \n",
      "APP_PRED_COUNT            5.262453       4.634594       0.000000   \n",
      "APP_PRED_RANGE            0.052289       0.045084       0.000000   \n",
      "APP_PRED_COUNT_NORM       1.603958       0.679373       0.000000   \n",
      "\n",
      "                               max  \n",
      "SK_ID_CURR           456250.000000  \n",
      "APP_PRED_MEAN             0.500715  \n",
      "APP_PRED_MAX              0.500715  \n",
      "APP_PRED_MIN              0.500715  \n",
      "APP_PRED_STD              0.229880  \n",
      "APP_PRED_COUNT           77.000000  \n",
      "APP_PRED_RANGE            0.427563  \n",
      "APP_PRED_COUNT_NORM       4.356709  \n",
      "Test data with fixed application predictions shape: (48744, 135)\n",
      "Adding network features to data...\n",
      "Training data with network features shape: (307511, 158)\n",
      "Test data with network features shape: (48744, 151)\n",
      "Preprocessing test data with network features...\n",
      "Preprocessing complete. Data shape: (48744, 154)\n",
      "Creating interaction features...\n",
      "Creating interaction features...\n",
      "Training final corrected model and generating predictions...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 24825, number of negative: 282686\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19849\n",
      "[LightGBM] [Info] Number of data points in the train set: 307511, number of used features: 159\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432486\n",
      "[LightGBM] [Info] Start training from score -2.432486\n",
      "Corrected submission saved to /Users/braidosan/Downloads/home-credit-default-risk/submission_fixed_v4.csv\n",
      "Submission predictions range: 0.0006071163682032269 to 0.9211360041793888\n",
      "Submission predictions mean: 0.06561866964111765\n",
      "\n",
      "Model Version Comparison:\n",
      "Version 1 (Application only): CV AUC = 0.8036 ± 0.0044\n",
      "Version 2 (Application + Bureau): CV AUC = 0.8257 ± 0.0031\n",
      "Version 3 (Application + Bureau + Network): CV AUC = 0.8317 ± 0.0040\n",
      "Version 4 (Fixed Version): CV AUC = 0.8317 ± 0.0040 (same CV, fixed test predictions)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fix test application predictions\n",
    "def fix_test_app_predictions():\n",
    "    \"\"\"\n",
    "    Fix the application-level predictions for the test set\n",
    "    \"\"\"\n",
    "    print(\"Fixing application-level predictions for test set...\")\n",
    "    \n",
    "    # 1. Get test previous applications\n",
    "    test_prev_apps = prev_df[prev_df['SK_ID_CURR'].isin(test_df['SK_ID_CURR'])]\n",
    "    print(f\"Test previous applications: {test_prev_apps.shape}\")\n",
    "    \n",
    "    # 2. Preprocess them\n",
    "    test_prev_features = preprocess_app_level_features(test_prev_apps)\n",
    "    \n",
    "    # 3. Generate predictions using app_level_model\n",
    "    X_test_prev = test_prev_features.drop(['SK_ID_CURR', 'SK_ID_PREV'], axis=1, errors='ignore')\n",
    "    if 'TARGET' in X_test_prev.columns:\n",
    "        X_test_prev = X_test_prev.drop('TARGET', axis=1)\n",
    "        \n",
    "    # Make sure X_test_prev has the same columns as the training data\n",
    "    missing_cols = set(app_level_model.feature_name_) - set(X_test_prev.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test_prev[col] = 0  # Add missing columns with default values\n",
    "    \n",
    "    # Use only the columns that were used during training\n",
    "    X_test_prev = X_test_prev[app_level_model.feature_name_]\n",
    "    \n",
    "    # Generate predictions\n",
    "    test_prev_preds = app_level_model.predict_proba(X_test_prev)[:, 1]\n",
    "    \n",
    "    # Add predictions back to the dataframe\n",
    "    test_app_preds = test_prev_features[['SK_ID_CURR', 'SK_ID_PREV']].copy()\n",
    "    test_app_preds['APP_PRED'] = test_prev_preds\n",
    "    \n",
    "    # 4. Aggregate predictions by customer\n",
    "    test_agg_preds = test_app_preds.groupby('SK_ID_CURR').agg({\n",
    "        'APP_PRED': ['mean', 'max', 'min', 'std', 'count']\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    test_agg_preds.columns = ['APP_PRED_' + col for col in ['MEAN', 'MAX', 'MIN', 'STD', 'COUNT']]\n",
    "    \n",
    "    # Reset index\n",
    "    test_agg_preds = test_agg_preds.reset_index()\n",
    "    \n",
    "    # Handle missing std values (customers with only one application)\n",
    "    test_agg_preds['APP_PRED_STD'] = test_agg_preds['APP_PRED_STD'].fillna(0)\n",
    "    \n",
    "    # Add range feature\n",
    "    test_agg_preds['APP_PRED_RANGE'] = test_agg_preds['APP_PRED_MAX'] - test_agg_preds['APP_PRED_MIN']\n",
    "    \n",
    "    # Add normalized count (log transform to handle skewness)\n",
    "    test_agg_preds['APP_PRED_COUNT_NORM'] = np.log1p(test_agg_preds['APP_PRED_COUNT'])\n",
    "    \n",
    "    # 5. Fill missing values for customers with no applications\n",
    "    full_test_preds = test_df[['SK_ID_CURR']].merge(test_agg_preds, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    # Fill missing values for customers with no previous applications\n",
    "    for col in test_agg_preds.columns:\n",
    "        if col == 'SK_ID_CURR':\n",
    "            continue\n",
    "            \n",
    "        if col in ['APP_PRED_MEAN', 'APP_PRED_MAX', 'APP_PRED_MIN']:\n",
    "            # For customers with no previous applications, use a default value of 0.5\n",
    "            full_test_preds[col] = full_test_preds[col].fillna(0.5)\n",
    "        else:\n",
    "            full_test_preds[col] = full_test_preds[col].fillna(0)\n",
    "    \n",
    "    # 6. Check the fixed predictions\n",
    "    print(f\"Fixed test application predictions shape: {full_test_preds.shape}\")\n",
    "    print(\"\\nFixed test application prediction statistics:\")\n",
    "    print(full_test_preds.describe().T[['mean', 'std', 'min', 'max']])\n",
    "    \n",
    "    return full_test_preds\n",
    "\n",
    "# Fix test application predictions\n",
    "fixed_test_app_preds = fix_test_app_predictions()\n",
    "\n",
    "# Step 2: Recreate test data with correct predictions\n",
    "test_with_bureau_fixed = test_with_bureau.copy()\n",
    "\n",
    "# Remove incorrect app prediction columns\n",
    "app_cols = [col for col in test_with_bureau.columns if 'APP_PRED' in col]\n",
    "test_with_bureau_fixed = test_with_bureau_fixed.drop(columns=app_cols)\n",
    "\n",
    "# Add fixed app predictions\n",
    "test_with_bureau_fixed = test_with_bureau_fixed.merge(fixed_test_app_preds, on='SK_ID_CURR', how='left')\n",
    "\n",
    "print(f\"Test data with fixed application predictions shape: {test_with_bureau_fixed.shape}\")\n",
    "\n",
    "# Step 3: Reprocess the data for consistency\n",
    "# Add network features to our corrected data\n",
    "train_with_network_fixed = train_with_network  # Original train data is fine\n",
    "test_with_network_fixed = add_network_features_to_data(train_enhanced, \n",
    "                                                       test_with_bureau_fixed, \n",
    "                                                       network_features_df)[1]  # Get only test data\n",
    "\n",
    "# Preprocess data with network features\n",
    "train_network_processed_fixed = train_network_processed  # Original train processed data is fine\n",
    "test_network_processed_fixed = preprocess_network_data(test_with_network_fixed, is_training=False)\n",
    "\n",
    "# Step 4: Create additional validation features from app and bureau predictions\n",
    "def create_interaction_features(df):\n",
    "    \"\"\"\n",
    "    Create interaction features between application and bureau predictions\n",
    "    \"\"\"\n",
    "    print(\"Creating interaction features...\")\n",
    "    \n",
    "    # App x Bureau interactions\n",
    "    if 'APP_PRED_MEAN' in df.columns and 'BUREAU_PRED_MEAN' in df.columns:\n",
    "        df['APP_X_BUREAU_MEAN'] = df['APP_PRED_MEAN'] * df['BUREAU_PRED_MEAN']\n",
    "        df['APP_X_BUREAU_MAX'] = df['APP_PRED_MAX'] * df['BUREAU_PRED_MAX']\n",
    "        df['APP_X_BUREAU_MIN'] = df['APP_PRED_MIN'] * df['BUREAU_PRED_MIN']\n",
    "        df['APP_MINUS_BUREAU_MEAN'] = df['APP_PRED_MEAN'] - df['BUREAU_PRED_MEAN']\n",
    "        df['APP_MINUS_BUREAU_MAX'] = df['APP_PRED_MAX'] - df['BUREAU_PRED_MAX']\n",
    "    \n",
    "    # Network interactions\n",
    "    if 'NET_DAYS_DECISION_MEAN' in df.columns:\n",
    "        if 'APP_PRED_MEAN' in df.columns:\n",
    "            df['APP_X_NET_DAYS'] = df['APP_PRED_MEAN'] * df['NET_DAYS_DECISION_MEAN'].abs()\n",
    "        if 'BUREAU_PRED_MEAN' in df.columns:\n",
    "            df['BUREAU_X_NET_DAYS'] = df['BUREAU_PRED_MEAN'] * df['NET_DAYS_DECISION_MEAN'].abs()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add interaction features\n",
    "train_final = create_interaction_features(train_network_processed_fixed)\n",
    "test_final = create_interaction_features(test_network_processed_fixed)\n",
    "\n",
    "# Step 5: Train final model and generate corrected submission\n",
    "def train_final_fixed_model(train_data, test_data):\n",
    "    \"\"\"\n",
    "    Train the final model with fixed test predictions and make predictions\n",
    "    \"\"\"\n",
    "    print(\"Training final corrected model and generating predictions...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_train = train_data.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "    y_train = train_data['TARGET']\n",
    "    \n",
    "    # Make sure test data has the same columns as training data\n",
    "    missing_cols = set(X_train.columns) - set(test_data.columns)\n",
    "    for col in missing_cols:\n",
    "        test_data[col] = 0  # Add missing columns with default values\n",
    "        \n",
    "    # Use only the columns that exist in training data\n",
    "    X_test = test_data[X_train.columns]\n",
    "    \n",
    "    # Initialize LightGBM classifier with the parameters that worked well in CV\n",
    "    final_model = lgbm.LGBMClassifier(\n",
    "        n_estimators=550,  # Based on average from CV\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=32,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_split_gain=0.01,\n",
    "        min_child_weight=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model on all training data\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions on test data\n",
    "    test_preds = final_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission = pd.DataFrame({\n",
    "        'SK_ID_CURR': test_data['SK_ID_CURR'],\n",
    "        'TARGET': test_preds\n",
    "    })\n",
    "    \n",
    "    # Save submission to CSV\n",
    "    submission_path = os.path.join(DATA_DIR, \"submission_fixed_v4.csv\")\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(f\"Corrected submission saved to {submission_path}\")\n",
    "    print(f\"Submission predictions range: {submission['TARGET'].min()} to {submission['TARGET'].max()}\")\n",
    "    print(f\"Submission predictions mean: {submission['TARGET'].mean()}\")\n",
    "    \n",
    "    return submission, final_model\n",
    "\n",
    "# Train final fixed model and make predictions\n",
    "fixed_submission, final_fixed_model = train_final_fixed_model(train_final, test_final)\n",
    "\n",
    "# Step 6: Save the fixed model version\n",
    "version_info = {\n",
    "    'version': 'two_stage_v4_fixed',\n",
    "    'cv_auc': 0.8317,  # Same CV AUC as before since train data is unchanged\n",
    "    'cv_std': 0.0040,\n",
    "    'description': 'Fixed version of two-stage model with application, bureau and network features',\n",
    "}\n",
    "\n",
    "# Create a results directory if it doesn't exist\n",
    "results_dir = os.path.join(DATA_DIR, 'model_versions')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save submission with version number\n",
    "fixed_submission.to_csv(os.path.join(results_dir, 'submission_two_stage_v4_fixed.csv'), index=False)\n",
    "\n",
    "print(\"\\nModel Version Comparison:\")\n",
    "print(\"Version 1 (Application only): CV AUC = 0.8036 ± 0.0044\")\n",
    "print(\"Version 2 (Application + Bureau): CV AUC = 0.8257 ± 0.0031\")\n",
    "print(\"Version 3 (Application + Bureau + Network): CV AUC = 0.8317 ± 0.0040\")\n",
    "print(\"Version 4 (Fixed Version): CV AUC = 0.8317 ± 0.0040 (same CV, fixed test predictions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3753b7c7-1bdb-4df2-ad69-eae8b1b8ab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APP_PRED features in test data after fix:\n",
      "       APP_PRED_MEAN  APP_PRED_MAX  APP_PRED_MIN  APP_PRED_STD  \\\n",
      "count   48744.000000  48744.000000  48744.000000  48744.000000   \n",
      "mean        0.091107      0.120213      0.067924      0.021113   \n",
      "std         0.063338      0.069155      0.066643      0.017445   \n",
      "min         0.007564      0.007564      0.006013      0.000000   \n",
      "25%         0.065863      0.081856      0.041731      0.008335   \n",
      "50%         0.078956      0.104955      0.054145      0.019680   \n",
      "75%         0.096638      0.137876      0.072251      0.029811   \n",
      "max         0.500715      0.500715      0.500715      0.229880   \n",
      "\n",
      "       APP_PRED_COUNT  APP_PRED_RANGE  APP_PRED_COUNT_NORM  \n",
      "count    48744.000000    48744.000000         48744.000000  \n",
      "mean         5.262453        0.052289             1.603958  \n",
      "std          4.634594        0.045084             0.679373  \n",
      "min          0.000000        0.000000             0.000000  \n",
      "25%          2.000000        0.014960             1.098612  \n",
      "50%          4.000000        0.046686             1.609438  \n",
      "75%          7.000000        0.077493             2.079442  \n",
      "max         77.000000        0.427563             4.356709  \n"
     ]
    }
   ],
   "source": [
    "# Check that APP_PRED features are now properly populated in test data\n",
    "print(\"APP_PRED features in test data after fix:\")\n",
    "app_pred_cols = [col for col in test_final.columns if 'APP_PRED' in col]\n",
    "print(test_final[app_pred_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "69efc1a1-6314-4aee-a2f4-0b6adab1311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features in fixed model:\n",
      "                        feature  importance\n",
      "40                 EXT_SOURCE_2         523\n",
      "39                 EXT_SOURCE_1         449\n",
      "7                   AMT_ANNUITY         437\n",
      "161              APP_X_NET_DAYS         434\n",
      "122                APP_PRED_MIN         412\n",
      "120               APP_PRED_MEAN         411\n",
      "41                 EXT_SOURCE_3         393\n",
      "129             BUREAU_PRED_MIN         341\n",
      "16                DAYS_EMPLOYED         328\n",
      "17            DAYS_REGISTRATION         328\n",
      "6                    AMT_CREDIT         327\n",
      "18              DAYS_ID_PUBLISH         324\n",
      "137           APP_X_BUREAU_MEAN         316\n",
      "134                   AGE_YEARS         304\n",
      "14   REGION_POPULATION_RELATIVE         291\n",
      "93       DAYS_LAST_PHONE_CHANGE         287\n",
      "15                   DAYS_BIRTH         286\n",
      "149        NET_AMT_ANNUITY_MEAN         284\n",
      "139            APP_X_BUREAU_MIN         282\n",
      "135      CREDIT_TO_INCOME_RATIO         281\n"
     ]
    }
   ],
   "source": [
    "# Check feature importance in the fixed model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': final_fixed_model.feature_name_,\n",
    "    'importance': final_fixed_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 features in fixed model:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "71c085e4-1fb0-4b84-9e50-0730ab596645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (48744, 2)\n",
      "Submission columns: ['SK_ID_CURR', 'TARGET']\n",
      "Sample of submission:\n",
      "   SK_ID_CURR    TARGET\n",
      "0      100001  0.033167\n",
      "1      100005  0.086829\n",
      "2      100013  0.006331\n",
      "3      100028  0.045227\n",
      "4      100038  0.113963\n"
     ]
    }
   ],
   "source": [
    "# Verify submission format\n",
    "print(\"Submission shape:\", fixed_submission.shape)\n",
    "print(\"Submission columns:\", fixed_submission.columns.tolist())\n",
    "print(\"Sample of submission:\")\n",
    "print(fixed_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bc87e1d8-12ac-4ba1-af7e-bde1adc7d30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed submission prediction stats:\n",
      "count    48744.000000\n",
      "mean         0.065619\n",
      "std          0.088635\n",
      "min          0.000607\n",
      "25%          0.013875\n",
      "50%          0.032553\n",
      "75%          0.078958\n",
      "max          0.921136\n",
      "Name: TARGET, dtype: float64\n",
      "OOF prediction stats:\n",
      "count    307511.000000\n",
      "mean          0.079953\n",
      "std           0.114123\n",
      "min           0.000279\n",
      "25%           0.015369\n",
      "50%           0.036739\n",
      "75%           0.092838\n",
      "max           0.988294\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of fixed submission predictions\n",
    "print(\"Fixed submission prediction stats:\")\n",
    "print(fixed_submission['TARGET'].describe())\n",
    "\n",
    "# Distribution of OOF predictions from CV\n",
    "print(\"OOF prediction stats:\")\n",
    "print(pd.Series(network_oof_preds).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7bd66619-c341-47c5-ae73-e87a09f57a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble submission created!\n"
     ]
    }
   ],
   "source": [
    "# Load both submissions\n",
    "original_sub = pd.read_csv(os.path.join(DATA_DIR, \"submission_full.csv\"))\n",
    "twostage_sub = pd.read_csv(os.path.join(DATA_DIR, \"model_versions\", \"submission_two_stage_v4_fixed.csv\"))\n",
    "\n",
    "# If that doesn't work, try with the direct path\n",
    "# twostage_sub = pd.read_csv(\"/Users/braidosan/Downloads/home-credit-default-risk/submission_fixed_v4.csv\")\n",
    "\n",
    "# Create ensemble (weighted average)\n",
    "ensemble_sub = original_sub.copy()\n",
    "ensemble_sub['TARGET'] = 0.7 * original_sub['TARGET'] + 0.3 * twostage_sub['TARGET']\n",
    "\n",
    "# Save ensemble submission\n",
    "ensemble_sub.to_csv(os.path.join(DATA_DIR, \"submission_ensemble.csv\"), index=False)\n",
    "print(\"Ensemble submission created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f32f4e3-0e55-4f4f-99e5-67653e087dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ensemble with weights 0.60/0.40\n",
      "Created ensemble with weights 0.65/0.35\n",
      "Created ensemble with weights 0.70/0.30\n",
      "Created ensemble with weights 0.75/0.25\n",
      "Created ensemble with weights 0.80/0.20\n",
      "Created ensemble with weights 0.85/0.15\n",
      "Created ensemble with weights 0.90/0.10\n",
      "\n",
      "All ensemble variations created!\n"
     ]
    }
   ],
   "source": [
    "# Load both submissions\n",
    "original_sub = pd.read_csv(os.path.join(DATA_DIR, \"submission_full.csv\"))\n",
    "twostage_sub = pd.read_csv(os.path.join(DATA_DIR, \"submission_fixed_v4.csv\"))\n",
    "\n",
    "# Try different weights to find the optimal blend\n",
    "weights = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "for original_weight in weights:\n",
    "    # Calculate two-stage weight\n",
    "    twostage_weight = 1 - original_weight\n",
    "    \n",
    "    # Create ensemble with this weight\n",
    "    ensemble_sub = original_sub.copy()\n",
    "    ensemble_sub['TARGET'] = (original_weight * original_sub['TARGET'] + \n",
    "                             twostage_weight * twostage_sub['TARGET'])\n",
    "    \n",
    "    # Save ensemble submission with weight in filename\n",
    "    filename = f\"submission_ensemble_{int(original_weight*100)}-{int(twostage_weight*100)}.csv\"\n",
    "    ensemble_sub.to_csv(os.path.join(DATA_DIR, filename), index=False)\n",
    "    \n",
    "    print(f\"Created ensemble with weights {original_weight:.2f}/{twostage_weight:.2f}\")\n",
    "\n",
    "print(\"\\nAll ensemble variations created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a654f53-cf4a-444d-a84d-1f90e008af99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
